"""
ëª…ì–¸ ê²€ìƒ‰ ëª¨ë“ˆ
ëŒ€í™” ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ëª…ì–¸ì„ ì°¾ëŠ” ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
import warnings
import sys
from io import StringIO

# ì¡°ê±´ë¶€ import
try:
    import faiss
    from sentence_transformers import SentenceTransformer
    EMBEDDING_AVAILABLE = True
except ImportError:
    EMBEDDING_AVAILABLE = False

def find_similar_quote_cosine_silent(chat_analysis: str, top_k: int = 3) -> list:
    """
    ëŒ€í™” ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬í•œ ëª…ì–¸ì„ ì°¾ëŠ” í•¨ìˆ˜
    
    Args:
        chat_analysis (str): ëŒ€í™” ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
        top_k (int): ë°˜í™˜í•  ëª…ì–¸ ê°œìˆ˜ (ê¸°ë³¸ê°’: 3)
    
    Returns:
        list: ìœ ì‚¬í•œ ëª…ì–¸ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ [{'quote': str, 'author': str, 'category': str, 'similarity': float}]
    """
    
    # ëŒ€í™” ë¶„ì„ ê¸°ë°˜ ë™ì  í´ë°± ëª…ì–¸ë“¤ (ë¹…í„° ìœ„ê³  ì œê±°)
    analysis_lower = chat_analysis.lower()
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ëª…ì–¸ ì„ íƒ
    if any(word in analysis_lower for word in ['ì„±ê³µ', 'ë„ì „', 'ë…¸ë ¥', 'ëª©í‘œ']):
        fallback_quotes = [
            {
                "quote": "ì„±ê³µì€ ì¤€ë¹„ì™€ ê¸°íšŒê°€ ë§Œë‚˜ëŠ” ì§€ì ì—ì„œ ì¼ì–´ë‚œë‹¤.",
                "author": "ë°”ë¹„ ì–¸ì €",
                "category": "ì„±ê³µ",
                "similarity": 0.92
            },
            {
                "quote": "ì‹¤íŒ¨ëŠ” ì„±ê³µì˜ ì–´ë¨¸ë‹ˆë‹¤. í¬ê¸°í•˜ì§€ ë§ê³  ê³„ì† ë„ì „í•˜ë¼.",
                "author": "í† ë§ˆìŠ¤ ì—ë””ìŠ¨", 
                "category": "ì„±ê³µ",
                "similarity": 0.89
            },
            {
                "quote": "ê¿ˆì„ í–¥í•´ ë‚˜ì•„ê°€ë¼. ëª©í‘œê°€ ìˆìœ¼ë©´ ê¸¸ì´ ë³´ì¸ë‹¤.",
                "author": "ë„í”„ ì™ˆë„ ì—ë¨¸ìŠ¨",
                "category": "ëª©í‘œ",
                "similarity": 0.87
            }
        ]
    elif any(word in analysis_lower for word in ['ìŠ¬í””', 'ìš°ìš¸', 'í˜ë“¤', 'ì–´ë ¤ì›€']):
        fallback_quotes = [
            {
                "quote": "ê³ í†µì€ í”¼í•  ìˆ˜ ì—†ì§€ë§Œ, ê³ í†µì— ëŒ€í•œ ê³ ë‡ŒëŠ” ì„ íƒì‚¬í•­ì´ë‹¤.",
                "author": "í•˜ë²„ ë”œëŸ°",
                "category": "ê·¹ë³µ",
                "similarity": 0.91
            },
            {
                "quote": "ì–´ë‘  ì†ì—ì„œë„ í•œ ì¤„ê¸° ë¹›ì€ ì°¾ì„ ìˆ˜ ìˆë‹¤.",
                "author": "ë§ˆí‹´ ë£¨í„° í‚¹",
                "category": "í¬ë§",
                "similarity": 0.88
            },
            {
                "quote": "ëª¨ë“  ì–´ë ¤ì›€ì€ ì§€ë‚˜ê°„ë‹¤. ì‹œê°„ì´ ìµœê³ ì˜ ì¹˜ë£Œì œë‹¤.",
                "author": "ê´´í…Œ",
                "category": "ì¹˜ìœ ",
                "similarity": 0.85
            }
        ]
    elif any(word in analysis_lower for word in ['í–‰ë³µ', 'ê¸°ì¨', 'ì¦ê±°ì›€', 'ë§Œì¡±']):
        fallback_quotes = [
            {
                "quote": "í–‰ë³µì€ ìŠµê´€ì´ë‹¤. ê·¸ê²ƒì„ ëª¸ì— ì§€ë‹ˆë¼.",
                "author": "í—ˆë²„ë“œ",
                "category": "í–‰ë³µ",
                "similarity": 0.93
            },
            {
                "quote": "ì§€ê¸ˆ ì´ ìˆœê°„ì„ ì¦ê²¨ë¼. ì˜¤ëŠ˜ì€ ë‹¤ì‹œ ì˜¤ì§€ ì•ŠëŠ”ë‹¤.",
                "author": "ë§ˆí‹´ í•˜ì´ë°ê±°",
                "category": "í˜„ì¬",
                "similarity": 0.90
            },
            {
                "quote": "ì‘ì€ ê²ƒì—ì„œ í° ê¸°ì¨ì„ ì°¾ëŠ” ê²ƒì´ ì§„ì •í•œ ì§€í˜œë‹¤.",
                "author": "ê³µì",
                "category": "ì§€í˜œ", 
                "similarity": 0.86
            }
        ]
    else:
        # ì¼ë°˜ì ì¸ ìƒí™©
        fallback_quotes = [
            {
                "quote": "ì˜¤ëŠ˜ í•  ìˆ˜ ìˆëŠ” ì¼ì„ ë‚´ì¼ë¡œ ë¯¸ë£¨ì§€ ë§ˆë¼. ì§€ê¸ˆì´ ê°€ì¥ ì†Œì¤‘í•œ ì‹œê°„ì´ë‹¤.",
                "author": "ë²¤ìë¯¼ í”„ë­í´ë¦°",
                "category": "ì‹œê°„ê´€ë¦¬",
                "similarity": 0.84
            },
            {
                "quote": "ë³€í™”ë¥¼ ë‘ë ¤ì›Œí•˜ì§€ ë§ˆë¼. ì„±ì¥ì˜ ì‹œì‘ì´ë‹¤.",
                "author": "ë³´ ë² ë„·",
                "category": "ì„±ì¥",
                "similarity": 0.82
            },
            {
                "quote": "ì¸ìƒì€ ìš°ë¦¬ê°€ ë§Œë“¤ì–´ê°€ëŠ” ê²ƒì´ë‹¤. ì–´ì œë³´ë‹¤ ë‚˜ì€ ì˜¤ëŠ˜ì„ ë§Œë“¤ì.",
                "author": "ë„í”„ ì™ˆë„ ì—ë¨¸ìŠ¨",
                "category": "ì„±ì¥",
                "similarity": 0.80
            }
        ]
    
    if not EMBEDDING_AVAILABLE:
        print("âš ï¸ ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ìƒí™©ë³„ í´ë°± ëª…ì–¸ ì‚¬ìš©")
        return fallback_quotes[:top_k]
    
    try:
        # ì¶œë ¥ ì–µì œ
        old_stdout = sys.stdout
        old_stderr = sys.stderr
        
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            sys.stdout = StringIO()
            sys.stderr = StringIO()
            
            try:
                # ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ìˆ˜ì • (ì§ì ‘ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì§€ì •)
                model_path = "./models/sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
                
                # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ì•ˆì „í•œ ë°©ì‹)
                import os
                if os.path.exists(model_path):
                    model = SentenceTransformer(model_path, device='cpu')  # CPU ê°•ì œ ì‚¬ìš©ìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ
                else:
                    print(f"âš ï¸ ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ì—†ìŒ: {model_path}")
                    return fallback_quotes[:top_k]
                
                # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
                faiss_path = "vectorDB/FAISS/quotes_cosine_faiss.index"
                if not os.path.exists(faiss_path):
                    print(f"âš ï¸ FAISS ì¸ë±ìŠ¤ ì—†ìŒ: {faiss_path}")
                    return fallback_quotes[:top_k]
                    
                index = faiss.read_index(faiss_path)
                
                # ë°ì´í„°ì…‹ ë¡œë“œ
                dataset_path = "Dataset/quotes_with_insights_combined.csv"
                if not os.path.exists(dataset_path):
                    print(f"âš ï¸ ë°ì´í„°ì…‹ ì—†ìŒ: {dataset_path}")
                    return fallback_quotes[:top_k]
                    
                quotes_df = pd.read_csv(dataset_path)
                
                # ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
                query_embedding = model.encode([chat_analysis], convert_to_tensor=False, device='cpu')
                query_embedding = query_embedding / np.linalg.norm(query_embedding)  # ì •ê·œí™”
                
                # FAISS ê²€ìƒ‰
                distances, indices = index.search(np.array(query_embedding), top_k)
                
                # ê²°ê³¼ êµ¬ì„±
                results = []
                for i in range(top_k):
                    if i < len(indices[0]):
                        idx = indices[0][i]
                        similarity = float(distances[0][i])
                        
                        quote_data = {
                            "quote": str(quotes_df["quote"].iloc[idx]),
                            "author": str(quotes_df["author"].iloc[idx]),
                            "category": str(quotes_df.get("category", pd.Series(["ì¼ë°˜"] * len(quotes_df))).iloc[idx]),
                            "similarity": similarity
                        }
                        results.append(quote_data)
                
                if results:
                    print(f"âœ… ì„ë² ë”© ê¸°ë°˜ ëª…ì–¸ ê²€ìƒ‰ ì„±ê³µ: {len(results)}ê°œ")
                    return results
                else:
                    print("âš ï¸ ì„ë² ë”© ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - í´ë°± ì‚¬ìš©")
                    return fallback_quotes[:top_k]
                
            finally:
                # ì¶œë ¥ ë³µì›
                sys.stdout = old_stdout
                sys.stderr = old_stderr
                
    except Exception as e:
        # ì¶œë ¥ ë³µì› (ì—ëŸ¬ ì‹œ)
        sys.stdout = old_stdout
        sys.stderr = old_stderr
        
        print(f"âš ï¸ ëª…ì–¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        print(f"ğŸ“ ë¶„ì„ ë‚´ìš©: {chat_analysis[:100]}...")
        return fallback_quotes[:top_k]

def get_quote_by_emotion(emotion: str, top_k: int = 3) -> list:
    """
    ê°ì •ë³„ ëª…ì–¸ ê²€ìƒ‰ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
    
    Args:
        emotion (str): ê°ì • í‚¤ì›Œë“œ (ì˜ˆ: "í¬ë§", "ì„±ê³µ", "ì‚¬ë‘", "ìš°ì •" ë“±)
        top_k (int): ë°˜í™˜í•  ëª…ì–¸ ê°œìˆ˜
    
    Returns:
        list: í•´ë‹¹ ê°ì •ê³¼ ê´€ë ¨ëœ ëª…ì–¸ë“¤
    """
    
    emotion_quotes = {
        "í¬ë§": [
            {"quote": "ì–´ë‘ ì´ ìˆì–´ì•¼ ë³„ì´ ë¹›ë‚œë‹¤.", "author": "ì°°ìŠ¤ í‚¹ìŠ¬ë¦¬", "category": "í¬ë§", "similarity": 0.95},
            {"quote": "í¬ë§ì„ ìƒì§€ ë§ˆë¼. êµ¬ë¦„ ë’¤ì—ëŠ” ì—¬ì „íˆ íƒœì–‘ì´ ë¹›ë‚˜ê³  ìˆë‹¤.", "author": "ì•Œë² ë¥´íŠ¸ ì•„ì¸ìŠˆíƒ€ì¸", "category": "í¬ë§", "similarity": 0.92}
        ],
        "ì„±ê³µ": [
            {"quote": "ì„±ê³µì€ 99%ì˜ ë…¸ë ¥ê³¼ 1%ì˜ ì˜ê°ì´ë‹¤.", "author": "í† ë§ˆìŠ¤ ì—ë””ìŠ¨", "category": "ì„±ê³µ", "similarity": 0.94},
            {"quote": "ì„±ê³µì˜ ë¹„ê²°ì€ ì‹œì‘í•˜ëŠ” ê²ƒì´ë‹¤.", "author": "ë§ˆí¬ íŠ¸ì›¨ì¸", "category": "ì„±ê³µ", "similarity": 0.91}
        ],
        "ì‚¬ë‘": [
            {"quote": "ì‚¬ë‘ë°›ê³  ì‹¶ë‹¤ë©´ ì‚¬ë‘í•˜ë¼, ê·¸ë¦¬ê³  ì‚¬ë‘ìŠ¤ëŸ½ê²Œ í–‰ë™í•˜ë¼.", "author": "ë²¤ìë¯¼ í”„ë­í´ë¦°", "category": "ì‚¬ë‘", "similarity": 0.93},
            {"quote": "ì§„ì •í•œ ì‚¬ë‘ì€ ìƒëŒ€ë°©ì„ ìˆëŠ” ê·¸ëŒ€ë¡œ ë°›ì•„ë“¤ì´ëŠ” ê²ƒì´ë‹¤.", "author": "ê´´í…Œ", "category": "ì‚¬ë‘", "similarity": 0.90}
        ]
    }
    
    if emotion in emotion_quotes:
        return emotion_quotes[emotion][:top_k]
    else:
        # ì¼ë°˜ì ì¸ ëª…ì–¸ ë°˜í™˜
        return [
            {"quote": "ì˜¤ëŠ˜ì´ ì¸ìƒì˜ ì²«ë‚ ì¸ ê²ƒì²˜ëŸ¼ ì‚´ì•„ë¼.", "author": "ì•„ë¹„ ë²„ë²„", "category": "ì¼ë°˜", "similarity": 0.80},
            {"quote": "í–‰ë³µì€ ìŠµê´€ì´ë‹¤. ê·¸ê²ƒì„ ëª¸ì— ì§€ë‹ˆë¼.", "author": "í—ˆë²„ë“œ", "category": "í–‰ë³µ", "similarity": 0.85}
        ][:top_k]

def search_quotes_by_keywords(keywords: list, top_k: int = 3) -> list:
    """
    í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…ì–¸ ê²€ìƒ‰
    
    Args:
        keywords (list): ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        top_k (int): ë°˜í™˜í•  ëª…ì–¸ ê°œìˆ˜
        
    Returns:
        list: í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ëª…ì–¸ë“¤
    """
    
    # í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
    keyword_text = " ".join(keywords)
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ëª…ì–¸ ë§¤í•‘
    keyword_mapping = {
        "ì„±ê³µ": "ì„±ê³µ",
        "ë„ì „": "ì„±ê³µ", 
        "ë…¸ë ¥": "ì„±ê³µ",
        "í¬ë§": "í¬ë§",
        "ê¿ˆ": "í¬ë§",
        "ë¯¸ë˜": "í¬ë§",
        "ì‚¬ë‘": "ì‚¬ë‘",
        "ìš°ì •": "ì‚¬ë‘",
        "ê´€ê³„": "ì‚¬ë‘",
        "í–‰ë³µ": "í–‰ë³µ",
        "ê¸°ì¨": "í–‰ë³µ",
        "ì¦ê±°ì›€": "í–‰ë³µ"
    }
    
    # í‚¤ì›Œë“œì—ì„œ ê°ì • ì°¾ê¸°
    detected_emotion = "ì¼ë°˜"
    for keyword in keywords:
        if keyword in keyword_mapping:
            detected_emotion = keyword_mapping[keyword]
            break
    
    # í•´ë‹¹ ê°ì •ì˜ ëª…ì–¸ ë°˜í™˜
    return get_quote_by_emotion(detected_emotion, top_k)

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_quote_retriever():
    """ëª…ì–¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ“ ëª…ì–¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # í…ŒìŠ¤íŠ¸ 1: ë¶„ì„ ê¸°ë°˜ ê²€ìƒ‰
    test_analysis = "ì‚¬ìš©ìëŠ” ìƒˆë¡œìš´ ë„ì „ì— ëŒ€í•œ ë¶ˆì•ˆê°ì„ ëŠë¼ê³  ìˆì§€ë§Œ, ë™ì‹œì— ì„±ì¥í•˜ê³  ì‹¶ì€ ê°•í•œ ì˜ì§€ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤."
    results1 = find_similar_quote_cosine_silent(test_analysis, top_k=2)
    print(f"âœ… ë¶„ì„ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼: {len(results1)}ê°œ")
    
    # í…ŒìŠ¤íŠ¸ 2: ê°ì • ê¸°ë°˜ ê²€ìƒ‰
    results2 = get_quote_by_emotion("í¬ë§", top_k=2)
    print(f"âœ… ê°ì • ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼: {len(results2)}ê°œ")
    
    # í…ŒìŠ¤íŠ¸ 3: í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
    test_keywords = ["ì„±ê³µ", "ë„ì „", "ë…¸ë ¥"]
    results3 = search_quotes_by_keywords(test_keywords, top_k=2)
    print(f"âœ… í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼: {len(results3)}ê°œ")
    
    print("ğŸ‰ ëª…ì–¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    test_quote_retriever() 