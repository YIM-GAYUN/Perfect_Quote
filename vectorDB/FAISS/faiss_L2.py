# FAISS ì¸ë±ìŠ¤ ìƒì„±(L2ê±°ë¦¬) ë° í…ŒìŠ¤íŠ¸

from sentence_transformers import SentenceTransformer
import pandas as pd
import numpy as np
from tqdm import tqdm
import faiss

# 1. ë²¡í„° ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
quote_embeddings = np.load("insights_combined_embeddings.npy")

# 2. FAISS ì¸ë±ìŠ¤ ìƒì„± (L2 ê±°ë¦¬ ê¸°ë°˜)
embedding_dim = quote_embeddings.shape[1]  # ë²¡í„° ì°¨ì› (384)
index = faiss.IndexFlatL2(embedding_dim)

# 3. FAISS ì¸ë±ìŠ¤ì— ëª…ì–¸ ë²¡í„° ì¶”ê°€
index.add(quote_embeddings)

# 4. FAISS ì¸ë±ìŠ¤ ì €ì¥
faiss.write_index(index, "quotes_L2_faiss.index")

print("âœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥ ì™„ë£Œ!")

def find_similar_quote(user_text, top_k=3):
    # FAISS ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
    index = faiss.read_index("quotes_L2_faiss.index")

    # SBERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")

    # ì›ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = pd.read_csv("quotes_with_insights_combined.csv")

    # ì‚¬ìš©ì ì…ë ¥ì„ ë²¡í„°ë¡œ ë³€í™˜
    user_embedding = model.encode([user_text], convert_to_tensor=False)

    # FAISS ê²€ìƒ‰ (ìµœê·¼ì ‘ ì´ì›ƒ ì°¾ê¸°)
    distances, indices = index.search(np.array(user_embedding), top_k)

    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“Œ ì‚¬ìš©ìì˜ ì…ë ¥ ë¬¸ì¥:", user_text)
    print("ğŸ” ìœ ì‚¬í•œ ëª…ì–¸ ì¶”ì²œ:")

    for i in range(top_k):
        quote = df["quote"].iloc[indices[0][i]]
        author = df["author"].iloc[indices[0][i]]
        category = df["category"].iloc[indices[0][i]]
        print(f"\nâœ¨ ì¶”ì²œ {i+1}: {quote}\nğŸ–Šï¸ ì‘ê°€: {author}\nğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {category}\n(ìœ ì‚¬ë„ ê±°ë¦¬: {distances[0][i]:.4f})")

# ì‚¬ìš© ì˜ˆì‹œ
user_input = "Today is a very proud day because I did my best."
find_similar_quote(user_input)