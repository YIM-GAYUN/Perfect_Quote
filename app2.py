from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime
import json
import uuid
import time
import random
import threading
import os
from dotenv import load_dotenv

# LangGraph ë° LangChain ê´€ë ¨ imports
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_upstage import ChatUpstage
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage
from typing import TypedDict, List, Dict, Any, Annotated, Optional

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ import
from utils.system_prompt import SYSTEM_PROMPT

# ì„ë² ë”© ê¸°ë°˜ ëª…ì–¸ ê²€ìƒ‰ (ì¡°ê±´ë¶€)
EMBEDDING_AVAILABLE = False
EMBEDDING_LOADING = False

try:
    from quote_embedding.quote_similarity_search import find_similar_quotes
    EMBEDDING_AVAILABLE = True
    print("âœ… ì„ë² ë”© ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ ì„ë² ë”© ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ğŸ”„ ê¸°ë³¸ ëª…ì–¸ ì‹œìŠ¤í…œ ì‚¬ìš©")

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

app = Flask(__name__)
CORS(app)

# ì±—ë´‡ ìƒíƒœ ì •ì˜
class ChatbotState(TypedDict):
    # ì‚¬ìš©ì ì •ë³´
    user_id: Annotated[str, "User ID"]
    thread_num: Annotated[str, "Session ID"]
    
    # ëŒ€í™” ì •ë³´
    user_message: Annotated[str, "User Message"]
    chatbot_message: Annotated[str, "Chatbot Message"]
    timestamp: Annotated[str, "Timestamp of the conversation"]
    chat_history: Annotated[ChatMessageHistory, "chat history of user and ai"]
    status: Annotated[str, "Status of the conversation"]
    
    # ëŒ€í™” ë¶„ì„ ì •ë³´
    chat_analysis: Annotated[str, "Analysis of the conversation"]
    retrieved_quotes_and_authors: Annotated[Dict[str, str] | List[tuple[str, str]], "Retrieved 3 quotes and 3 authors from vector db"]
    quote: Annotated[str, "Quote for the conversation"]
    author: Annotated[str, "Author of the quote"]
    keywords: Annotated[List[str], "Keywords of the conversation"]
    advice: Annotated[str, "Advice for the conversation"]
    
    # ëª…ì–¸ ì„ íƒ ê¸°ëŠ¥ì„ ìœ„í•œ í•„ë“œë“¤
    candidate_quotes: Annotated[List[Dict], "List of candidate quotes with similarity scores"]
    current_quote_index: Annotated[int, "Current quote index being presented"]
    quote_selection_complete: Annotated[bool, "Whether quote selection is complete"]

# LangGraph ë…¸ë“œ í•¨ìˆ˜ë“¤
def validate_user_input(state: ChatbotState) -> ChatbotState:
    """ì‚¬ìš©ì ì…ë ¥ ê²€ì¦"""
    user_input = state["user_message"]
    if not isinstance(user_input, str):
        raise TypeError("User message must be a string")
    
    user_input = user_input.strip()
    if not user_input:
        raise ValueError("User message cannot be empty")
        
    if len(user_input) > 150:
        raise ValueError("User message cannot be longer than 150 characters")
    
    return {
        **state,
        "user_message": user_input
    }

def _init_llm():
    """LLM ì´ˆê¸°í™”"""
    return ChatUpstage(
        model="solar-pro",
        temperature=0.7,
    )

def _build_chain():
    """ì±—ë´‡ ì²´ì¸ ë¹Œë“œ"""
    llm = _init_llm()
    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        ("user", "{user_input}")
    ])
    chain = prompt | llm  
    return chain

def chatbot(state: ChatbotState) -> ChatbotState:
    """ì±—ë´‡ ì‘ë‹µ ìƒì„±"""
    # Initialize chat history if empty
    chat_history = state["chat_history"]
    if not chat_history:
        chat_history = ChatMessageHistory()
        
    # Format chat history for prompt if needed
    formatted_history = ""
    if chat_history.messages:
        formatted_history = "\n".join([
            f"{'User' if isinstance(msg, HumanMessage) else 'Assistant'}: {msg.content}"
            for msg in chat_history.messages
        ])
        
    chain = _build_chain()
    response = chain.invoke({
        "user_input": f"{formatted_history}\n\nUser: {state['user_message']}" if formatted_history else state["user_message"]
    })

    return {
        **state,
        "chatbot_message": str(response.content),
    }

def save_history(state: ChatbotState) -> ChatbotState:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥"""
    chat_history = state["chat_history"]
    chat_history.add_messages([
        HumanMessage(content=state["user_message"]),
        AIMessage(content=state["chatbot_message"])
    ])

    return {
        **state,
        "chat_history": chat_history 
    }

def _build_analysis_chain():
    """ëŒ€í™” ë¶„ì„ ì²´ì¸ ë¹Œë“œ"""
    llm = _init_llm()
    analysis_prompt = """
ë‹¹ì‹ ì€ ëŒ€í™” ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœì™€ ìƒí™©
2. ëŒ€í™”ì˜ ì£¼ìš” ì£¼ì œì™€ ê´€ì‹¬ì‚¬
3. ì‚¬ìš©ìê°€ ê²ªê³  ìˆëŠ” ì–´ë ¤ì›€ì´ë‚˜ ê³ ë¯¼
4. ëŒ€í™”ì˜ ì „ì²´ì ì¸ í†¤ê³¼ ë¶„ìœ„ê¸°

ë¶„ì„ì€ ê°ê´€ì ì´ê³  ì •í™•í•´ì•¼ í•˜ë©°, ì‚¬ìš©ìì˜ ê°œì¸ì •ë³´ë¥¼ ë³´í˜¸í•˜ë©´ì„œë„ ì˜ë¯¸ìˆëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", analysis_prompt),
        ("user", "ë‹¤ìŒ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¶„ì„í•˜ë¼. \n\n{chat_history}")
    ])
    chain = prompt | llm
    return chain

def analyze_chat_history(state: ChatbotState) -> ChatbotState:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¶„ì„"""
    chat_history = state["chat_history"]

    # ëŒ€í™” í„´ ìˆ˜ê°€ 10í„´ ì´ìƒì´ë©´ ë¶„ì„ì„ í•œë‹¤.
    if len(chat_history.messages) < 10:
        raise ValueError("Chat history must be at least 10 messages")
    
    # ë¶„ì„ ì²´ì¸ì„ ìƒì„±í•˜ê³  ì‹¤í–‰í•œë‹¤.
    analysis_chain = _build_analysis_chain()
    analysis_response = analysis_chain.invoke({
        "chat_history": str(chat_history)
    })
    chat_analysis = analysis_response.content
    return {
        **state,
        "chat_analysis": str(chat_analysis)
    }

def _build_advice_and_keywords_chain():
    """ì¡°ì–¸ ë° í‚¤ì›Œë“œ ìƒì„± ì²´ì¸ ë¹Œë“œ"""
    llm = _init_llm()
    advice_prompt = """
ëŒ€í™” ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ì œê³µí•´ì¤˜ìš”:

1. ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ì¡°ì–¸ì„ í•´ì¤˜ìš”. ì‚¬ìš©ìì—ê²ŒëŠ” 'ë‹¹ì‹ , ê·¸ëŒ€'ë¼ëŠ” 2ì¸ì¹­ í‘œí˜„ì„ ì‚¬ìš©í•´ìš”. (ìµœëŒ€ ì„¸ ë¬¸ì¥, ë¬¸í•™ì ì´ê³  ê°ì„±ì ì¸ ì–´íˆ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ì œê³µí•´ì¤˜ìš”.)

2. ëŒ€í™” ë‚´ìš©ì˜ í‚¤ì›Œë“œ (ìµœëŒ€ 5ê°œ, ì‰¼í‘œë¡œ êµ¬ë¶„)

í˜•ì‹:
ì¡°ì–¸: [ì¡°ì–¸ ë‚´ìš©]
í‚¤ì›Œë“œ: [í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3]
"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", advice_prompt),
        ("user", "{chat_history}")
    ])
    chain = prompt | llm
    return chain

def generate_advice(state: ChatbotState) -> ChatbotState:
    """ëŒ€í™” ë¶„ì„ì„ ë°”ë±¡ìœ¼ë¡œ ì‚¬ìš©ìì— ì í•©í•œ ì¡°ì–¸ì„ ìƒì„±í•œë‹¤."""
    llm = _build_advice_and_keywords_chain()

    chat_analysis = state["chat_analysis"]
    result = llm.invoke({"chat_history": chat_analysis})
    
    # ì‘ë‹µ í…ìŠ¤íŠ¸ íŒŒì‹±
    response_text = str(result.content)
    advice = "ëŒ€í™”ë¥¼ í†µí•´ í–‰ë³µì„ ì°¾ì•„ê°€ì‹œê¸¸ ë°”ëë‹ˆë‹¤." # ê¸°ë³¸ê°’
    keywords = ["ëŒ€í™”", "í–‰ë³µ", "ê³ ë¯¼"] # ê¸°ë³¸ê°’
    
    # ê¸°ë³¸ ëª…ì–¸ ë°ì´í„° (ëª…ì–¸ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
    default_quotes = [
        {
            "quote": "ì‹¤íŒ¨ëŠ” ì„±ê³µì˜ ì–´ë¨¸ë‹ˆë‹¤. í¬ê¸°í•˜ì§€ ë§ê³  ê³„ì† ë„ì „í•˜ë¼.",
            "author": "í† ë§ˆìŠ¤ ì—ë””ìŠ¨",
            "category": "ì„±ê³µ",
            "similarity": 0.892
        },
        {
            "quote": "ì–´ë ¤ì›€ì´ ìˆì„ ë•Œë§ˆë‹¤ ê¸°íšŒë„ í•¨ê»˜ ì˜¨ë‹¤. ìœ„ê¸°ëŠ” ê³§ ì „í™˜ì ì´ë‹¤.",
            "author": "ì•Œë² ë¥´íŠ¸ ì•„ì¸ìŠˆíƒ€ì¸", 
            "category": "í¬ë§",
            "similarity": 0.847
        },
        {
            "quote": "ì˜¤ëŠ˜ í•  ìˆ˜ ìˆëŠ” ì¼ì„ ë‚´ì¼ë¡œ ë¯¸ë£¨ì§€ ë§ˆë¼. ì§€ê¸ˆì´ ê°€ì¥ ì†Œì¤‘í•œ ì‹œê°„ì´ë‹¤.",
            "author": "ë²¤ìë¯¼ í”„ë­í´ë¦°",
            "category": "ì‹œê°„ê´€ë¦¬",
            "similarity": 0.823
        }
    ]
    
    retrieved_quotes_and_authors = default_quotes
    
    # ì„ë² ë”© ì‹œìŠ¤í…œì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ëª…ì–¸ ê²€ìƒ‰ ì‹œë„
    if EMBEDDING_AVAILABLE:
        try:
            # ëª…ì–¸ ê²€ìƒ‰ (ë¡œë”© ë©”ì‹œì§€ ì–µì œ)
            import warnings
            import sys
            from io import StringIO
            
            # ëª¨ë“  ì¶œë ¥ê³¼ ê²½ê³  ì–µì œ
            old_stdout = sys.stdout
            old_stderr = sys.stderr
            
            try:
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    sys.stdout = StringIO()
                    sys.stderr = StringIO()
                    
                    # ì„ë² ë”© ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
                    # quotes = find_similar_quotes(chat_analysis, top_k=3)
                    
            finally:
                # ì¶œë ¥ ë³µì›
                sys.stdout = old_stdout
                sys.stderr = old_stderr
            
            # ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦ (ì‹¤ì œ êµ¬í˜„ì— ë§ê²Œ ìˆ˜ì •)
            # if quotes and len(quotes) > 0:
            #     retrieved_quotes_and_authors = quotes
                
        except Exception as e:
            print(f"âš ï¸ ëª…ì–¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ê¸°ë³¸ ëª…ì–¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    try:
        lines = response_text.split('\n')
        for line in lines:
            if line.startswith('ì¡°ì–¸:'):
                advice = line.replace('ì¡°ì–¸:', '').strip()
            elif line.startswith('í‚¤ì›Œë“œ:'):
                keywords_text = line.replace('í‚¤ì›Œë“œ:', '').strip()
                keywords = [k.strip() for k in keywords_text.split(',')]
    except Exception:
        pass  # ê¸°ë³¸ê°’ ì‚¬ìš©
    
    return {
        **state,
        "retrieved_quotes_and_authors": retrieved_quotes_and_authors,
        "advice": advice,
        "keywords": keywords,
        "candidate_quotes": retrieved_quotes_and_authors,
        "current_quote_index": 0,
        "quote_selection_complete": False,
        "quote": "",
        "author": ""
    }

def present_quote(state: ChatbotState) -> ChatbotState:
    """í˜„ì¬ ì¸ë±ìŠ¤ì˜ ëª…ì–¸ì„ ì‚¬ìš©ìì—ê²Œ ì œì‹œí•œë‹¤."""
    candidate_quotes = state["candidate_quotes"]
    current_index = state["current_quote_index"]
    
    if not candidate_quotes:
        return {
            **state,
            "chatbot_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ì²œí•  ëª…ì–¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤.",
            "quote_selection_complete": True
        }
    
    # í˜„ì¬ ëª…ì–¸ ê°€ì ¸ì˜¤ê¸°
    current_quote = candidate_quotes[current_index]
    quote_text = current_quote["quote"]
    author_text = current_quote["author"]
    similarity = current_quote.get("similarity", 0)
    
    # ì‚¬ìš©ìì—ê²Œ ëª…ì–¸ ì œì‹œ
    message = f"ë‹¤ìŒ ëª…ì–¸ì€ ì–´ë– ì‹ ê°€ìš”?\n\nğŸ’¬ \"{quote_text}\"\nâœï¸ ì €ì: {author_text}\nğŸ“Š ìœ ì‚¬ë„: {similarity:.3f}\n\nì´ ëª…ì–¸ì„ ì„ íƒí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì˜ˆ/ì•„ë‹ˆì˜¤)"
    
    return {
        **state,
        "chatbot_message": message
    }

def validate_quote_input(state: ChatbotState) -> ChatbotState:
    """ëª…ì–¸ ì„ íƒì„ ìœ„í•œ ì‚¬ìš©ì ì…ë ¥ ê²€ì¦"""
    user_input = state["user_message"]
    if not isinstance(user_input, str):
        raise TypeError("User message must be a string")
    
    user_input = user_input.strip()
    if not user_input:
        raise ValueError("User message cannot be empty")
        
    return {
        **state,
        "user_message": user_input
    }

def process_quote_selection(state: ChatbotState) -> ChatbotState:
    """ì‚¬ìš©ìì˜ ëª…ì–¸ ì„ íƒ ì‘ë‹µì„ ì²˜ë¦¬í•œë‹¤."""
    user_input = state["user_message"].strip().lower()
    candidate_quotes = state["candidate_quotes"]
    current_index = state["current_quote_index"]
    
    if user_input in ['ì˜ˆ', 'yes', 'y', 'ë„¤', 'ì„ íƒ']:
        # í˜„ì¬ ëª…ì–¸ ì„ íƒ í™•ì •
        selected_quote = candidate_quotes[current_index]
        return {
            **state,
            "quote": selected_quote["quote"],
            "author": selected_quote["author"],
            "quote_selection_complete": True,
            "chatbot_message": "ì¢‹ì€ ì„ íƒì´ì—ìš”! ëª…ì–¸ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    elif user_input in ['ì•„ë‹ˆì˜¤', 'no', 'n', 'ì•„ë‹ˆ', 'ë‹¤ìŒ']:
        # ë‹¤ìŒ ëª…ì–¸ìœ¼ë¡œ ì´ë™ (ìˆœí™˜)
        next_index = (current_index + 1) % len(candidate_quotes)
        return {
            **state,
            "current_quote_index": next_index,
            "chatbot_message": "ë‹¤ìŒ ëª…ì–¸ì„ ë³´ì—¬ë“œë¦´ê²Œìš”!"
        }
    
    else:
        # ì˜ëª»ëœ ì…ë ¥
        return {
            **state,
            "chatbot_message": "'ì˜ˆ' ë˜ëŠ” 'ì•„ë‹ˆì˜¤'ë¡œ ë‹µí•´ì£¼ì„¸ìš”."
        }

# ë¶„ê¸° ì—£ì§€ ì •ì˜
def should_analyze_chat_history(state: ChatbotState) -> str:
    """ëŒ€í™” ë¶„ì„ ì—¬ë¶€ ê²°ì •"""
    if len(state["chat_history"].messages) >= 10:
        return "messages >= 10"
    else:
        return "messages < 10"

# LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
def create_chatbot_graph():
    """ì±—ë´‡ ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(ChatbotState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("validate_user_input", validate_user_input)
    workflow.add_node("chatbot", chatbot)
    workflow.add_node("save_history", save_history)
    workflow.add_node("analyze_chat_history", analyze_chat_history)
    workflow.add_node("generate_advice", generate_advice)

    # ì—£ì§€ ì—°ê²°
    workflow.add_edge(START, "validate_user_input")
    workflow.add_edge("validate_user_input", "chatbot")
    workflow.add_edge("chatbot", "save_history")

    # ì¡°ê±´ë¶€ ë¶„ê¸° ì¶”ê°€
    workflow.add_conditional_edges(
        "save_history",
        should_analyze_chat_history,
        path_map={
            "messages >= 10": "analyze_chat_history",
            "messages < 10": END
        }
    )

    # analyze_chat_historyì—ì„œ generate_adviceë¡œ
    workflow.add_edge("analyze_chat_history", "generate_advice")
    workflow.add_edge("generate_advice", END)
    
    return workflow.compile()

# ì „ì—­ ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤
chatbot_graph = create_chatbot_graph()

# ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
chatbot_sessions = {}
session_lock = threading.Lock()

def get_chatbot_state(user_id, thread_num):
    """ì‚¬ìš©ìë³„ ì±—ë´‡ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
    session_key = f"{user_id}_{thread_num}"
    
    with session_lock:
        if session_key not in chatbot_sessions:
            # ì´ˆê¸° ìƒíƒœ ìƒì„±
            initial_state = {
                "user_id": user_id,
                "thread_num": thread_num,
                "user_message": "",
                "chatbot_message": "",
                "timestamp": datetime.now().isoformat(),
                "chat_history": ChatMessageHistory(),
                "status": "pending",
                "quote": "",
                "author": "",
                "retrieved_quotes_and_authors": [],
                "candidate_quotes": [],
                "current_quote_index": 0,
                "quote_selection_complete": False,
                "chat_analysis": "",
                "keywords": [],
                "advice": ""
            }
            
            chatbot_sessions[session_key] = {
                'state': initial_state,
                'created_at': datetime.now(),
                'last_used': datetime.now()
            }
            print(f"ğŸš€ ìƒˆë¡œìš´ LangGraph ì±—ë´‡ ì„¸ì…˜ ìƒì„±: {session_key}")
        else:
            chatbot_sessions[session_key]['last_used'] = datetime.now()
    
    return chatbot_sessions[session_key]['state']

def run_chatbot_once(state, user_input):
    """ë‹¨ì¼ í„´ ëŒ€í™” ì‹¤í–‰"""
    # í˜„ì¬ ìƒíƒœì— ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ ì„¤ì •
    state["user_message"] = user_input
    state["timestamp"] = datetime.now().isoformat()

    # ê·¸ë˜í”„ ì‹¤í–‰
    result = chatbot_graph.invoke(state)
    return result

@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'OK',
        'timestamp': datetime.now().isoformat(),
        'activeConversations': len(chatbot_sessions),
        'model': 'Solar Pro API + LangGraph',
        'embedding_system': 'âœ… ACTIVE' if EMBEDDING_AVAILABLE else 'âš ï¸ FALLBACK',
        'message': 'ğŸ‰ LangGraph ê¸°ë°˜ ê³ ê¸‰ ì±—ë´‡ ì‹œìŠ¤í…œ í™œì„±í™”!'
    })

@app.route('/api/chat/send', methods=['POST'])
def send_message():
    """ë©”ì‹œì§€ ì „ì†¡ API - LangGraph ê¸°ë°˜"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['userId', 'threadNum', 'content']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        user_id = data['userId']
        thread_num = data['threadNum']
        content = data['content']
        
        print(f"ğŸ¤– LangGraph ì±—ë´‡ í˜¸ì¶œ - User: {user_id}, Message: {content}")
        
        # ì±—ë´‡ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        state = get_chatbot_state(user_id, thread_num)
        
        # ëª…ì–¸ ì„ íƒ ëª¨ë“œì¸ì§€ í™•ì¸
        if state.get('candidate_quotes') and not state.get('quote_selection_complete', False):
            # ëª…ì–¸ ì„ íƒ ëª¨ë“œ ì²˜ë¦¬
            state = validate_quote_input(state)
            state = process_quote_selection(state)
            
            # ì„ íƒì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if state.get('quote_selection_complete'):
                response_data = {
                    'userId': user_id,
                    'threadNum': thread_num,
                    'timestamp': datetime.now().isoformat(),
                    'status': 'quote_selected',
                    'content': state['chatbot_message'],
                    'quote': {
                        'id': str(uuid.uuid4()),
                        'text': state['quote'],
                        'author': state['author'],
                        'category': 'personalized'
                    },
                    'advice': state.get('advice', ''),
                    'keywords': state.get('keywords', []),
                    'model': 'Solar Pro + LangGraph'
                }
            else:
                # ë‹¤ìŒ ëª…ì–¸ ì œì‹œ
                state = present_quote(state)
                response_data = {
                    'userId': user_id,
                    'threadNum': thread_num,
                    'timestamp': datetime.now().isoformat(),
                    'status': 'quote_selection',
                    'content': state['chatbot_message'],
                    'quote': None,
                    'model': 'Solar Pro + LangGraph'
                }
        else:
            # ì¼ë°˜ ëŒ€í™” ëª¨ë“œ
            result = run_chatbot_once(state, content)
            
            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            session_key = f"{user_id}_{thread_num}"
            chatbot_sessions[session_key]['state'] = result
            
            response_data = {
                'userId': user_id,
                'threadNum': thread_num,
                'timestamp': result['timestamp'],
                'status': 'completed',
                'content': result['chatbot_message'],
                'quote': None,
                'model': 'Solar Pro + LangGraph'
            }
            
            # 10í„´ í›„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if len(result["chat_history"].messages) >= 10:
                if result.get('advice') and result.get('keywords'):
                    # ëª…ì–¸ ì„ íƒ ëª¨ë“œ ì‹œì‘
                    if result.get('candidate_quotes'):
                        result = present_quote(result)
                        chatbot_sessions[session_key]['state'] = result
                        response_data['status'] = 'quote_selection'
                        response_data['content'] = result['chatbot_message']
                        response_data['advice'] = result.get('advice', '')
                        response_data['keywords'] = result.get('keywords', [])
        
        return jsonify(response_data)
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return jsonify({
            'error': str(e),
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'model': 'Solar Pro + LangGraph'
        }), 500

@app.route('/api/chat/status', methods=['GET'])
def get_status():
    """ìƒíƒœ í™•ì¸ API (í´ë§ìš©)"""
    try:
        user_id = request.args.get('userId')
        thread_num = request.args.get('threadNum')
        
        if not user_id or not thread_num:
            return jsonify({'error': 'Missing userId or threadNum'}), 400
        
        # ì±—ë´‡ ìƒíƒœê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        session_key = f"{user_id}_{thread_num}"
        
        if session_key in chatbot_sessions:
            state = chatbot_sessions[session_key]['state']
            
            return jsonify({
                'userId': user_id,
                'threadNum': thread_num,
                'timestamp': datetime.now().isoformat(),
                'status': 'completed',
                'content': state.get('chatbot_message', ''),
                'quote': None,
                'model': 'Solar Pro + LangGraph'
            })
        else:
            return jsonify({
                'userId': user_id,
                'threadNum': thread_num,
                'timestamp': datetime.now().isoformat(),
                'status': 'pending',
                'content': '',
                'quote': None,
                'model': 'Solar Pro + LangGraph'
            })
            
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'model': 'Solar Pro + LangGraph'
        }), 500

if __name__ == '__main__':
    print("ğŸš€ LangGraph ê¸°ë°˜ ê³ ê¸‰ ì±—ë´‡ ì„œë²„ ì‹œì‘ ì¤‘...")
    print("ğŸ“¡ í¬íŠ¸: 3002")
    print("ğŸ”¥ ëª¨ë¸: Solar Pro API + LangGraph")
    print("ğŸ§  ê¸°ëŠ¥: ëŒ€í™” ë¶„ì„ + ê°œì¸í™”ëœ ëª…ì–¸ ì¶”ì²œ")
    print("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ: True")
    print("ğŸŒ CORS í™œì„±í™”ë¨")
    print("âœ¨ LangGraph ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ ê³ ê¸‰ ì±—ë´‡ ì‹œìŠ¤í…œ!")
    
    app.run(host='0.0.0.0', port=3002, debug=True)
