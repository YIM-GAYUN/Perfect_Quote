from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime
import json
import uuid
import time
import random
import threading

# LangGraph imports
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_upstage import ChatUpstage
from langchain_community.chat_message_histories import ChatMessageHistory
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, List, Dict, Any, Annotated, Optional

import os
from dotenv import load_dotenv

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ import
from utils.system_prompt import SYSTEM_PROMPT
from utils.analysis_prompt import ANALYSIS_PROMPT

# ëª…ì–¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ
try:
    from utils.quote_retriever import find_similar_quote_cosine_silent
    print("âœ… ëª…ì–¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
    QUOTE_RETRIEVER_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ ëª…ì–¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    QUOTE_RETRIEVER_AVAILABLE = False

# ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ì„ ìœ„í•œ imports (ì¡°ê±´ë¶€)
import pandas as pd
import numpy as np

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# === ìƒìˆ˜ ì •ì˜ ===
TURN_THRESHOLD = 20
EMBEDDING_AVAILABLE = False
EMBEDDING_LOADING = False
EMBEDDING_LIBS_AVAILABLE = True

# === ê¸°ë³¸ ëª…ì–¸ ë°ì´í„° ===
FALLBACK_QUOTES = {
    'general': [
        {"quote": "ì¸ìƒì€ ìš°ë¦¬ê°€ ë§Œë“¤ì–´ê°€ëŠ” ê²ƒì´ë‹¤. ì–´ì œë³´ë‹¤ ë‚˜ì€ ì˜¤ëŠ˜ì„ ë§Œë“¤ì.", "author": "ë„í”„ ì™ˆë„ ì—ë¨¸ìŠ¨", "category": "ì„±ì¥", "similarity": 0.88},
        {"quote": "ë³€í™”ë¥¼ ë‘ë ¤ì›Œí•˜ì§€ ë§ˆë¼. ì„±ì¥ì˜ ì‹œì‘ì´ë‹¤.", "author": "ë³´ ë² ë„·", "category": "ì„±ì¥", "similarity": 0.85},
        {"quote": "ì§€í˜œëŠ” ê²½í—˜ì—ì„œ ë‚˜ì˜¤ê³ , ê²½í—˜ì€ ë„ì „ì—ì„œ ë‚˜ì˜¨ë‹¤.", "author": "ì˜¤ìŠ¤ì¹´ ì™€ì¼ë“œ", "category": "ì§€í˜œ", "similarity": 0.82}
    ],
    'success': [
        {"quote": "ì„±ê³µì€ ì¤€ë¹„ì™€ ê¸°íšŒê°€ ë§Œë‚˜ëŠ” ì§€ì ì—ì„œ ì¼ì–´ë‚œë‹¤.", "author": "ë°”ë¹„ ì–¸ì €", "category": "ì„±ê³µ", "similarity": 0.92},
        {"quote": "ì‹¤íŒ¨ëŠ” ì„±ê³µì˜ ì–´ë¨¸ë‹ˆë‹¤. í¬ê¸°í•˜ì§€ ë§ê³  ê³„ì† ë„ì „í•˜ë¼.", "author": "í† ë§ˆìŠ¤ ì—ë””ìŠ¨", "category": "ì„±ê³µ", "similarity": 0.89},
        {"quote": "ê¿ˆì„ í–¥í•´ ë‚˜ì•„ê°€ë¼. ëª©í‘œê°€ ìˆìœ¼ë©´ ê¸¸ì´ ë³´ì¸ë‹¤.", "author": "ë„í”„ ì™ˆë„ ì—ë¨¸ìŠ¨", "category": "ëª©í‘œ", "similarity": 0.87}
    ],
    'hope': [
        {"quote": "ì–´ë‘  ì†ì—ì„œë„ í•œ ì¤„ê¸° ë¹›ì€ ì°¾ì„ ìˆ˜ ìˆë‹¤.", "author": "ë§ˆí‹´ ë£¨í„° í‚¹", "category": "í¬ë§", "similarity": 0.90},
        {"quote": "ëª¨ë“  ì–´ë ¤ì›€ì€ ì§€ë‚˜ê°„ë‹¤. ì‹œê°„ì´ ìµœê³ ì˜ ì¹˜ë£Œì œë‹¤.", "author": "ê´´í…Œ", "category": "ì¹˜ìœ ", "similarity": 0.87},
        {"quote": "ê³ í†µì€ í”¼í•  ìˆ˜ ì—†ì§€ë§Œ, ê³ í†µì— ëŒ€í•œ ê³ ë‡ŒëŠ” ì„ íƒì‚¬í•­ì´ë‹¤.", "author": "í•˜ë²„ ë”œëŸ°", "category": "ê·¹ë³µ", "similarity": 0.84}
    ]
}

print("ğŸ”§ ì„ë² ë”© ì‹œìŠ¤í…œ ê°•ì œ í™œì„±í™”")

try:
    import faiss
    from sentence_transformers import SentenceTransformer
    print("âœ… ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ğŸ”„ ëŸ°íƒ€ì„ì— ë‹¤ì‹œ ì‹œë„í•  ì˜ˆì •")

app = Flask(__name__)
CORS(app)

# === LangGraph State ì •ì˜ ===
class ChatbotState(TypedDict):
    # ì‚¬ìš©ì ì •ë³´
    user_id: Annotated[str, "User ID"]
    thread_num: Annotated[str, "Session ID"]
    
    # ëŒ€í™” ì •ë³´
    user_message: Annotated[str, "User Message"]
    chatbot_message: Annotated[str, "Chatbot Message"]
    timestamp: Annotated[str, "Timestamp of the conversation"]
    chat_history: Annotated[ChatMessageHistory, "chat history of user and ai"]
    status: Annotated[str, "Status of the conversation"]
    
    # ëŒ€í™” ë¶„ì„ ì •ë³´
    chat_analysis: Annotated[str, "Analysis of the conversation"]
    retrieved_quotes_and_authors: Annotated[Dict[str, str] | List[tuple[str, str]], "Retrieved 3 quotes and 3 authors from vector db"]
    quote: Annotated[str, "Quote for the conversation"]
    author: Annotated[str, "Author of the quote"]
    keywords: Annotated[List[str], "Keywords of the conversation"]
    advice: Annotated[str, "Advice for the conversation"]
    
    # ëª…ì–¸ ì„ íƒ ê¸°ëŠ¥ì„ ìœ„í•œ í•„ë“œë“¤
    candidate_quotes: Annotated[List[Dict], "List of candidate quotes with similarity scores"]
    current_quote_index: Annotated[int, "Current quote index being presented"]
    quote_selection_complete: Annotated[bool, "Whether quote selection is complete"]

# === ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ ===
class LLMChainBuilder:
    """LLM ì²´ì¸ ìƒì„±ì„ ìœ„í•œ í†µí•© í´ë˜ìŠ¤"""
    
    @staticmethod
    def _init_llm():
        return ChatUpstage(
            model="solar-pro",
            temperature=0.7,
            max_tokens=300,
        )
    
    @classmethod
    def build_chat_chain(cls):
        """ì¼ë°˜ ì±„íŒ…ìš© ì²´ì¸"""
        llm = cls._init_llm()
        prompt = ChatPromptTemplate.from_messages([
            ("system", SYSTEM_PROMPT),
            ("user", "{user_input}")
        ])
        return prompt | llm
    
    @classmethod
    def build_analysis_chain(cls):
        """ëŒ€í™” ë¶„ì„ìš© ì²´ì¸"""
        llm = cls._init_llm()
        prompt = ChatPromptTemplate.from_messages([
            ("system", ANALYSIS_PROMPT),
            ("user", "ë‹¤ìŒ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¶„ì„í•˜ë¼. \\n\\n{chat_history}")
        ])
        return prompt | llm
    
    @classmethod
    def build_advice_chain(cls):
        """ì¡°ì–¸ ë° í‚¤ì›Œë“œ ìƒì„±ìš© ì²´ì¸"""
        llm = cls._init_llm()
        prompt = ChatPromptTemplate.from_messages([
            ("system", ANALYSIS_PROMPT + "\n\në¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ë‘ ê°€ì§€ë¥¼ ì œê³µí•´ì¤˜ìš”.:\n1. ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ì¡°ì–¸ì„ í•´ì¤˜ìš”. ì‚¬ìš©ìì—ê²ŒëŠ” 'ë‹¹ì‹ , ê·¸ëŒ€'ë¼ëŠ” 2ì¸ì¹­ í‘œí˜„ì„ ì‚¬ìš©í•´ìš”. (ìµœëŒ€ ì„¸ ë¬¸ì¥, ë¬¸í•™ì ì´ê³  ê°ì„±ì ì¸ ì–´íˆ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹œì ˆí•˜ê²Œ ì œê³µí•´ì¤˜ìš”.)\n2. ëŒ€í™” ë‚´ìš©ì˜ í‚¤ì›Œë“œ (ìµœëŒ€ 5ê°œ, ì‰¼í‘œë¡œ êµ¬ë¶„)\n\ní˜•ì‹:\nì¡°ì–¸: [ì¡°ì–¸ ë‚´ìš©]\ní‚¤ì›Œë“œ: [í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3]"),
            ("user", "{chat_history}")
        ])
        return prompt | llm

class QuoteManager:
    """ëª…ì–¸ ê´€ë ¨ ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    @staticmethod
    def select_fallback_quotes(analysis_text: str) -> List[Dict]:
        """ë¶„ì„ ë‚´ìš©ì— ë”°ë¼ ì ì ˆí•œ fallback ëª…ì–¸ ì„ íƒ"""
        analysis_lower = analysis_text.lower()
        
        if any(word in analysis_lower for word in ['ì„±ê³µ', 'ë„ì „', 'ëª©í‘œ', 'ë…¸ë ¥']):
            return FALLBACK_QUOTES['success']
        elif any(word in analysis_lower for word in ['í˜ë“¤', 'ì–´ë ¤ì›€', 'ìŠ¬í””', 'ìš°ìš¸']):
            return FALLBACK_QUOTES['hope']
        else:
            return FALLBACK_QUOTES['general']
    
    @staticmethod
    def search_quotes(chat_analysis: str) -> List[Dict]:
        """ëª…ì–¸ ê²€ìƒ‰ (ë²¡í„° ê²€ìƒ‰ ë˜ëŠ” fallback)"""
        fallback_quotes = QuoteManager.select_fallback_quotes(chat_analysis)
        
        try:
            if QUOTE_RETRIEVER_AVAILABLE:
                import warnings
                import sys
                from io import StringIO
                
                # ëª¨ë“  ì¶œë ¥ê³¼ ê²½ê³  ì–µì œ
                old_stdout = sys.stdout
                old_stderr = sys.stderr
                
                try:
                    with warnings.catch_warnings():
                        warnings.simplefilter("ignore")
                        sys.stdout = StringIO()
                        sys.stderr = StringIO()
                        
                        quotes = find_similar_quote_cosine_silent(chat_analysis, top_k=3)
                        
                finally:
                    # ì¶œë ¥ ë³µì›
                    sys.stdout = old_stdout
                    sys.stderr = old_stderr
                
                # ê²€ìƒ‰ ê²°ê³¼ ê²€ì¦
                if quotes and len(quotes) > 0 and all('quote' in q and 'author' in q for q in quotes):
                    print(f"âœ… ëª…ì–¸ ê²€ìƒ‰ ì„±ê³µ: {len(quotes)}ê°œ í›„ë³´")
                    return quotes
                else:
                    print("âš ï¸ ëª…ì–¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì˜¬ë°”ë¥´ì§€ ì•Šì•„ ê¸°ë³¸ ëª…ì–¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    return fallback_quotes
            else:
                print("âš ï¸ quote_retriever ì‚¬ìš© ë¶ˆê°€ - ê¸°ë³¸ ëª…ì–¸ ì‚¬ìš©")
                return fallback_quotes

        except Exception as e:
            print(f"âš ï¸ ëª…ì–¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ê¸°ë³¸ ëª…ì–¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return fallback_quotes
    
    @staticmethod
    def format_quote_message(quote_data: Dict, current_index: int) -> str:
        """ëª…ì–¸ ì œì‹œ ë©”ì‹œì§€ í¬ë§·íŒ…"""
        quote_text = quote_data["quote"]
        author_text = quote_data["author"]
        similarity = quote_data.get("similarity", 0)
        
        return f"ë‹¤ìŒ ëª…ì–¸ì€ ì–´ë– ì‹ ê°€ìš”?\n\nğŸ’¬ \"{quote_text}\"\nâœï¸ ì €ì: {author_text}\nğŸ“Š ìœ ì‚¬ë„: {similarity:.3f}\n\nì´ ëª…ì–¸ì„ ì„ íƒí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì˜ˆ/ì•„ë‹ˆì˜¤)"

class ConversationHelper:
    """ëŒ€í™” ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤"""
    
    @staticmethod
    def is_quit_command(user_input: str) -> bool:
        """ì¢…ë£Œ ëª…ë ¹ì–´ í™•ì¸"""
        quit_commands = ['quit', 'exit', 'ì¢…ë£Œ']
        return any(cmd in user_input.strip().lower() for cmd in quit_commands)
    
    @staticmethod
    def parse_advice_response(response_text: str) -> tuple[str, List[str]]:
        """ì¡°ì–¸ ì‘ë‹µ íŒŒì‹±"""
        advice = "ëŒ€í™”ë¥¼ í†µí•´ í–‰ë³µì„ ì°¾ì•„ê°€ì‹œê¸¸ ë°”ëë‹ˆë‹¤."
        keywords = ["ëŒ€í™”", "í–‰ë³µ", "ê³ ë¯¼"]
        
        try:
            lines = response_text.split('\n')
            for line in lines:
                if line.startswith('ì¡°ì–¸:'):
                    advice = line.replace('ì¡°ì–¸:', '').strip()
                elif line.startswith('í‚¤ì›Œë“œ:'):
                    keywords_text = line.replace('í‚¤ì›Œë“œ:', '').strip()
                    keywords = [k.strip() for k in keywords_text.split(',')]
        except Exception:
            pass  # ê¸°ë³¸ê°’ ì‚¬ìš©
        
        return advice, keywords

# === LangGraph ë…¸ë“œ í•¨ìˆ˜ë“¤ ===
def validate_user_input(state: ChatbotState) -> ChatbotState:
    user_input = state["user_message"]
    if not isinstance(user_input, str):
        raise TypeError("User message must be a string")
    
    user_input = user_input.strip()
    if not user_input:
        raise ValueError("User message cannot be empty")
        
    if len(user_input) > 150:
        raise ValueError("User message cannot be longer than 150 characters")
    
    return {
        **state,
        "user_message": user_input,
        "status": "validated"
    }

def chatbot(state: ChatbotState) -> ChatbotState:
    # Initialize chat history if empty
    chat_history = state["chat_history"]
    if not chat_history:
        chat_history = ChatMessageHistory()
        
    # Format chat history for prompt if needed
    formatted_history = ""
    if chat_history.messages:
        formatted_history = "\n".join([
            f"{'User' if isinstance(msg, HumanMessage) else 'Assistant'}: {msg.content}"
            for msg in chat_history.messages[-6:]  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
        ])
        
    chain = LLMChainBuilder.build_chat_chain()
    response = chain.invoke({
        "user_input": f"{formatted_history}\n\nUser: {state['user_message']}" if formatted_history else state["user_message"]
    })

    return {
        **state,
        "chatbot_message": str(response.content),
        "timestamp": datetime.now().isoformat(),
        "status": "completed"
    }

def save_history(state: ChatbotState) -> ChatbotState:
    chat_history = state["chat_history"]

    chat_history.add_messages([
        HumanMessage(content=state["user_message"]),
        AIMessage(content=state["chatbot_message"])
    ])
    
    return {
        **state,
        "chat_history": chat_history 
    }

def analyze_chat_history(state: ChatbotState) -> ChatbotState:
    chat_history = state["chat_history"]

    # ì‚¬ìš©ìê°€ ì¢…ë£Œ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸
    user_input = state.get("user_message", "").strip().lower()
    is_quit_command = ConversationHelper.is_quit_command(user_input)
    
    # ëŒ€í™” í„´ ìˆ˜ê°€ TURN_THRESHOLD ì´ìƒì´ê±°ë‚˜ ì¢…ë£Œ ëª…ë ¹ì–´ê°€ ì…ë ¥ëœ ê²½ìš°ì—ë§Œ ë¶„ì„ì„ ì§„í–‰
    if len(chat_history.messages) < TURN_THRESHOLD and not is_quit_command:
        raise ValueError(f"Chat history must be at least {TURN_THRESHOLD} messages")
    
    # ë¶„ì„ ì²´ì¸ì„ ìƒì„±í•˜ê³  ì‹¤í–‰í•œë‹¤.
    analysis_chain = LLMChainBuilder.build_analysis_chain()
    analysis_response = analysis_chain.invoke({
        "chat_history": str(chat_history)
    })
    chat_analysis = analysis_response.content
    return {
        **state,
        "chat_analysis": str(chat_analysis)
    }

def generate_advice(state: ChatbotState) -> ChatbotState:
    """ëŒ€í™” ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì— ì í•©í•œ ì¡°ì–¸ì„ ìƒì„±í•œë‹¤."""
    chain = LLMChainBuilder.build_advice_chain()

    chat_analysis = state["chat_analysis"]
    result = chain.invoke({"chat_history": chat_analysis})
    
    # ì‘ë‹µ í…ìŠ¤íŠ¸ íŒŒì‹±
    advice, keywords = ConversationHelper.parse_advice_response(str(result.content))
    
    # ëª…ì–¸ ê²€ìƒ‰
    retrieved_quotes = QuoteManager.search_quotes(chat_analysis)

    return {**state,
        "retrieved_quotes_and_authors": retrieved_quotes,
        "advice": advice,
        "keywords": keywords,
        "candidate_quotes": retrieved_quotes,
        "current_quote_index": 0,
        "quote_selection_complete": False,
        "quote": "",
        "author": ""
    }

def present_quote(state: ChatbotState) -> ChatbotState:
    """í˜„ì¬ ì¸ë±ìŠ¤ì˜ ëª…ì–¸ì„ ì‚¬ìš©ìì—ê²Œ ì œì‹œí•œë‹¤."""
    candidate_quotes = state["candidate_quotes"]
    current_index = state["current_quote_index"]
    
    if not candidate_quotes:
        return {
            **state,
            "chatbot_message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ì²œí•  ëª…ì–¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ê² ìŠµë‹ˆë‹¤.",
            "quote_selection_complete": True
        }
    
    # í˜„ì¬ ëª…ì–¸ ê°€ì ¸ì˜¤ê¸°
    current_quote = candidate_quotes[current_index]
    message = QuoteManager.format_quote_message(current_quote, current_index)
    
    return {
        **state,
        "chatbot_message": message
    }

def process_quote_selection(state: ChatbotState) -> ChatbotState:
    """ì‚¬ìš©ìì˜ ëª…ì–¸ ì„ íƒ ì‘ë‹µì„ ì²˜ë¦¬í•œë‹¤."""
    user_input = state["user_message"].strip().lower()
    candidate_quotes = state["candidate_quotes"]
    current_index = state["current_quote_index"]
    
    if user_input in ['ì˜ˆ', 'yes', 'y', 'ë„¤', 'ì„ íƒ']:
        # í˜„ì¬ ëª…ì–¸ ì„ íƒ í™•ì •
        selected_quote = candidate_quotes[current_index]
        return {
            **state,
            "quote": selected_quote["quote"],
            "author": selected_quote["author"],
            "quote_selection_complete": True,
            "chatbot_message": "ì¢‹ì€ ì„ íƒì´ì—ìš”! ëª…ì–¸ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    
    elif user_input in ['ì•„ë‹ˆì˜¤', 'no', 'n', 'ì•„ë‹ˆ', 'ë‹¤ìŒ']:
        # ë‹¤ìŒ ëª…ì–¸ìœ¼ë¡œ ì´ë™ (ìˆœí™˜)
        next_index = (current_index + 1) % len(candidate_quotes)
        return {
            **state,
            "current_quote_index": next_index,
            "chatbot_message": "ë‹¤ìŒ ëª…ì–¸ì„ ë³´ì—¬ë“œë¦´ê²Œìš”!"
        }
    
    else:
        # ì˜ëª»ëœ ì…ë ¥
        return {
            **state,
            "chatbot_message": "'ì˜ˆ' ë˜ëŠ” 'ì•„ë‹ˆì˜¤'ë¡œ ë‹µí•´ì£¼ì„¸ìš”."
        }

# === ë¶„ê¸° ì—£ì§€ ì •ì˜ ===
def should_analyze_chat_history(state: ChatbotState) -> str:
    # ì‚¬ìš©ìê°€ ì¢…ë£Œ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•œ ê²½ìš° ì²´í¬
    user_input = state.get("user_message", "").strip().lower()
    
    if ConversationHelper.is_quit_command(user_input):
        return f"messages >= {TURN_THRESHOLD}"
    
    if len(state["chat_history"].messages) >= TURN_THRESHOLD:
        return f"messages >= {TURN_THRESHOLD}"
    else:
        return f"messages < {TURN_THRESHOLD}"

# === LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± ===
workflow = StateGraph(ChatbotState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("validate_user_input", validate_user_input)
workflow.add_node("chatbot", chatbot)
workflow.add_node("save_history", save_history)
workflow.add_node("analyze_chat_history", analyze_chat_history)
workflow.add_node("generate_advice", generate_advice)
workflow.add_node("present_quote", present_quote)
workflow.add_node("process_quote_selection", process_quote_selection)

# ì—£ì§€ ì—°ê²°
workflow.add_edge(START, "validate_user_input")
workflow.add_edge("validate_user_input", "chatbot")
workflow.add_edge("chatbot", "save_history")

# ì¡°ê±´ë¶€ ë¶„ê¸° ì¶”ê°€
workflow.add_conditional_edges(
    "save_history",
    should_analyze_chat_history,
    path_map={
        f"messages >= {TURN_THRESHOLD}": "analyze_chat_history",
        f"messages < {TURN_THRESHOLD}": END
    }
)

# analyze_chat_historyì—ì„œ generate_adviceë¡œ
workflow.add_edge("analyze_chat_history", "generate_advice")
workflow.add_edge("generate_advice", "present_quote")
workflow.add_edge("present_quote", END)
workflow.add_edge("process_quote_selection", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
graph = workflow.compile()

# === í†µí•©ëœ ì±—ë´‡ í´ë˜ìŠ¤ ===
class EnhancedSolarChatbot:
    def __init__(self):
        self._init_state()
        self.quote_selection_mode = False
        print("ğŸš€ Enhanced Solar Chatbot with LangGraph ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_state(self):
        """ìƒíƒœ ì´ˆê¸°í™”"""
        self.state = {
            "user_id": "",
            "thread_num": "",
            "user_message": "",
            "chatbot_message": "",
            "timestamp": "",
            "chat_history": ChatMessageHistory(),
            "status": "",
            "quote": "",
            "author": "",
            "retrieved_quotes_and_authors": [],
            "candidate_quotes": [],
            "current_quote_index": 0,
            "quote_selection_complete": False,
            "chat_analysis": "",
            "keywords": [],
            "advice": ""
        }
    
    def run_chatbot_once(self, user_input, user_id, thread_num):
        """ë‹¨ì¼ í„´ ëŒ€í™” ì‹¤í–‰"""
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        self.state["user_message"] = user_input
        self.state["user_id"] = user_id
        self.state["thread_num"] = thread_num

        try:
            # ëª…ì–¸ ì„ íƒ ëª¨ë“œì¸ì§€ í™•ì¸
            if self.state.get('candidate_quotes') and not self.state.get('quote_selection_complete', False):
                self.quote_selection_mode = True
                
            if self.quote_selection_mode:
                # ëª…ì–¸ ì„ íƒ ëª¨ë“œ ì²˜ë¦¬
                self.state = validate_user_input(self.state)
                self.state = process_quote_selection(self.state)
                
                # ì„ íƒì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                if self.state.get('quote_selection_complete'):
                    print(f"âœ… ëª…ì–¸ ì„ íƒ ì™„ë£Œ: {self.state['quote'][:50]}...")
                    self.quote_selection_mode = False
                    return self.state
                else:
                    # ë‹¤ìŒ ëª…ì–¸ ì œì‹œ
                    self.state = present_quote(self.state)
                    return self.state
            else:
                # ì¼ë°˜ ëŒ€í™” ëª¨ë“œ - LangGraph ì‹¤í–‰
                result = graph.invoke(self.state)
                self.state.update(result)
                
                # exit ëª…ë ¹ì–´ë‚˜ TURN_THRESHOLDí„´ í›„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
                if (len(self.state["chat_history"].messages) >= TURN_THRESHOLD or 
                    ConversationHelper.is_quit_command(user_input)):
                    
                    if self.state.get('advice') and self.state.get('keywords'):
                        print(f"ğŸ‰ ëŒ€í™” ì™„ë£Œ - ë¶„ì„ ê²°ê³¼ ì¤€ë¹„ë¨")
                        
                        # ëª…ì–¸ ì„ íƒ ëª¨ë“œ ì‹œì‘
                        if self.state.get('candidate_quotes'):
                            print("ğŸ”„ ëª…ì–¸ ì„ íƒ ëª¨ë“œ ì‹œì‘")
                            self.quote_selection_mode = True
                
                return self.state
                
        except Exception as e:
            print(f"âŒ ì±—ë´‡ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return {
                **self.state,
                "chatbot_message": "ì£„ì†¡í•´ìš”, ì§€ê¸ˆ ëŒ€í™”í•˜ëŠ”ë° ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê² ì–´ìš”?",
                "status": "error"
            }
    
    def get_conversation_summary(self):
        """ëŒ€í™” ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        return {
            "message_count": len(self.state["chat_history"].messages),
            "analysis_ready": len(self.state["chat_history"].messages) >= TURN_THRESHOLD,
            "quote_selection_mode": self.quote_selection_mode,
            "quote_selected": bool(self.state.get("quote")),
            "advice": self.state.get("advice", ""),
            "keywords": self.state.get("keywords", [])
        }

# === ì„¸ì…˜ ê´€ë¦¬ ===
chatbot_sessions = {}
session_lock = threading.Lock()

def get_chatbot_instance(user_id, thread_num):
    """ì‚¬ìš©ìë³„ Enhanced Solar ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
    session_key = f"{user_id}_{thread_num}"
    
    with session_lock:
        if session_key not in chatbot_sessions:
            chatbot_sessions[session_key] = {
                'chatbot': EnhancedSolarChatbot(),
                'created_at': datetime.now(),
                'last_used': datetime.now()
            }
            print(f"ğŸš€ ìƒˆë¡œìš´ Enhanced Solar ì±—ë´‡ ì„¸ì…˜ ìƒì„±: {session_key}")
        else:
            chatbot_sessions[session_key]['last_used'] = datetime.now()
    
    return chatbot_sessions[session_key]['chatbot']

# === API ì—”ë“œí¬ì¸íŠ¸ë“¤ ===
@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    global EMBEDDING_LOADING, EMBEDDING_AVAILABLE
    
    # ì„ë² ë”© ì‹œìŠ¤í…œ ìƒíƒœ ê²°ì •
    if EMBEDDING_AVAILABLE:
        embedding_status = "âœ… ACTIVE"
        message = "ğŸ‰ Solar API + LangGraph + ê°œì¸í™” ëª…ì–¸ ì¶”ì²œ ì‹œìŠ¤í…œ ì™„ì „ í™œì„±í™”!"
    elif EMBEDDING_LOADING:
        embedding_status = "ğŸ”„ LOADING"
        message = "ğŸ“¥ Solar API + LangGraph ë™ì‘ ì¤‘ + ì„ë² ë”© ì‹œìŠ¤í…œ ë°±ê·¸ë¼ìš´ë“œ ë¡œë”© ì¤‘..."
    else:
        embedding_status = "âš ï¸ FALLBACK"
        message = "ğŸ”¥ Solar API + LangGraph ë™ì‘ ì¤‘ + ê¸°ë³¸ ëª…ì–¸ ì‹œìŠ¤í…œ ì‚¬ìš©"
    
    return jsonify({
        'status': 'OK',
        'timestamp': datetime.now().isoformat(),
        'activeConversations': len(chatbot_sessions),
        'model': 'Solar Pro API + LangGraph',
        'embedding_system': embedding_status,
        'embedding_available': EMBEDDING_AVAILABLE,
        'embedding_loading': EMBEDDING_LOADING,
        'quote_retriever_available': QUOTE_RETRIEVER_AVAILABLE,
        'message': message
    })

@app.route('/api/chat/send', methods=['POST'])
def send_message():
    """ë©”ì‹œì§€ ì „ì†¡ API - LangGraph ê¸°ë°˜ Enhanced Solar ì±—ë´‡ ì‚¬ìš©"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['userId', 'threadNum', 'content']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        user_id = data['userId']
        thread_num = data['threadNum']
        content = data['content']
        
        print(f"ğŸ¤– Enhanced Solar API í˜¸ì¶œ - User: {user_id}, Message: {content}")
        
        # Enhanced Solar ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        chatbot = get_chatbot_instance(user_id, thread_num)
        
        # LangGraphë¡œ ì‘ë‹µ ìƒì„±
        result_state = chatbot.run_chatbot_once(content, user_id, thread_num)
        
        ai_response = result_state.get('chatbot_message', 'ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        print(f"âœ¨ Enhanced Solar API ì‘ë‹µ: {ai_response}")
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            'userId': user_id,
            'threadNum': thread_num,
            'timestamp': result_state.get('timestamp', datetime.now().isoformat()),
            'status': result_state.get('status', 'completed'),
            'content': ai_response,
            'quote': None,
            'model': 'Solar Pro + LangGraph',
            'embedding_system': 'Enhanced FAISS',
            'conversation_summary': chatbot.get_conversation_summary()
        }
        
        # ëª…ì–¸ ì„ íƒì´ ì™„ë£Œëœ ê²½ìš°
        if result_state.get('quote_selection_complete') and result_state.get('quote'):
            response_data['quote'] = {
                'id': str(uuid.uuid4()),
                'text': result_state['quote'],
                'author': result_state['author'],
                'advice': result_state.get('advice', ''),
                'keywords': result_state.get('keywords', []),
                'method': 'langgraph_enhanced_selection'
            }
            print(f"ğŸ“œ ìµœì¢… ëª…ì–¸ ì„ íƒ ì™„ë£Œ: {result_state['quote'][:50]}... - {result_state['author']}")
            print(f"ğŸ¯ ì¡°ì–¸: {result_state.get('advice', '')}")
            print(f"ğŸ”‘ í‚¤ì›Œë“œ: {result_state.get('keywords', [])}")
        
        # TURN_THRESHOLD í„´ ë¶„ì„ ì™„ë£Œ ì‹œ ì¶”ê°€ ì •ë³´
        if len(result_state.get('chat_history', ChatMessageHistory()).messages) >= TURN_THRESHOLD:
            if result_state.get('advice'):
                response_data['analysis_complete'] = True
                response_data['advice'] = result_state.get('advice', '')
                response_data['keywords'] = result_state.get('keywords', [])
                print(f"ğŸ‰ ëŒ€í™” ë¶„ì„ ì™„ë£Œ - ì¡°ì–¸: {result_state.get('advice', '')}")
        
        return jsonify(response_data)
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return jsonify({
            'error': str(e),
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'model': 'Solar Pro + LangGraph'
        }), 500

@app.route('/api/chat/status', methods=['GET'])
def get_status():
    """ìƒíƒœ í™•ì¸ API (í´ë§ìš©)"""
    try:
        user_id = request.args.get('userId')
        thread_num = request.args.get('threadNum')
        
        if not user_id or not thread_num:
            return jsonify({'error': 'Missing userId or threadNum'}), 400
        
        # ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        session_key = f"{user_id}_{thread_num}"
        
        if session_key in chatbot_sessions:
            chatbot = chatbot_sessions[session_key]['chatbot']
            
            return jsonify({
                'userId': user_id,
                'threadNum': thread_num,
                'timestamp': datetime.now().isoformat(),
                'status': 'active',
                'model': 'Solar Pro + LangGraph',
                'embedding_system': 'Enhanced FAISS',
                'conversation_summary': chatbot.get_conversation_summary()
            })
        else:
            return jsonify({
                'userId': user_id,
                'threadNum': thread_num,
                'timestamp': datetime.now().isoformat(),
                'status': 'inactive',
                'model': 'Solar Pro + LangGraph',
                'embedding_system': 'Enhanced FAISS'
            })
            
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'model': 'Solar Pro + LangGraph'
        }), 500

if __name__ == '__main__':
    print("ğŸš€ Enhanced Solar API + LangGraph ì„œë²„ ì‹œì‘ ì¤‘...")
    print("ğŸ“¡ í¬íŠ¸: 3001")
    print("ğŸ”¥ ëª¨ë¸: Solar Pro API + LangGraph StateGraph")
    print("ğŸ§  ì„ë² ë”©: Enhanced SentenceTransformer + FAISS")
    print("ğŸ“Š ëª…ì–¸ ê²€ìƒ‰: utils.quote_retriever")
    print("ğŸ¯ ë¶„ì„: ëŒ€í™” ë‚´ìš© ë¶„ì„ + ëª…ì–¸ ì„ íƒ")
    print("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ: False")
    print("ğŸŒ CORS í™œì„±í™”ë¨")
    print("âœ¨ LangGraph ê¸°ë°˜ ê°œì¸í™”ëœ ëª…ì–¸ ì¶”ì²œ ì‹œìŠ¤í…œ!")
    
    app.run(host='0.0.0.0', port=3001, debug=False, use_reloader=False)
