from flask import Flask, request, jsonify
from flask_cors import CORS
from datetime import datetime
import json
import uuid
import time
import random
import threading

# Solar API ê´€ë ¨ imports
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_upstage import ChatUpstage
from langchain_community.chat_message_histories import ChatMessageHistory
import os
from dotenv import load_dotenv

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ import
from utils.system_prompt import SYSTEM_PROMPT

# ì„ë² ë”© ê¸°ë°˜ ê²€ìƒ‰ì„ ìœ„í•œ imports (ì¡°ê±´ë¶€)
import pandas as pd
import numpy as np

# ì„ë² ë”© ì‹œìŠ¤í…œ ìƒíƒœ ì¶”ì 
EMBEDDING_AVAILABLE = False
EMBEDDING_LOADING = False

# ê°•ì œë¡œ ì„ë² ë”© ì‹œìŠ¤í…œ í™œì„±í™”
EMBEDDING_LIBS_AVAILABLE = True
print("ğŸ”§ ì„ë² ë”© ì‹œìŠ¤í…œ ê°•ì œ í™œì„±í™”")

try:
    import faiss
    from sentence_transformers import SentenceTransformer
    print("âœ… ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"âš ï¸ ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ğŸ”„ ëŸ°íƒ€ì„ì— ë‹¤ì‹œ ì‹œë„í•  ì˜ˆì •")

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

app = Flask(__name__)
CORS(app)

# ì‹¤ì œ Solar API + ì„ë² ë”© ê¸°ë°˜ ì±—ë´‡ í´ë˜ìŠ¤
class SolarChatbot:
    def __init__(self):
        self.chat_history = ChatMessageHistory()
        self.conversation_count = 0
        
        # Solar Pro LLM ì´ˆê¸°í™”
        self.llm = ChatUpstage(
            model="solar-pro",
            temperature=0.7,
            max_tokens=300,
        )
        
        # ì„ë² ë”© ì‹œìŠ¤í…œ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™”
        self.embedding_system_available = False
        if EMBEDDING_LIBS_AVAILABLE:
            print("ğŸ”„ ì„ë² ë”© ì‹œìŠ¤í…œ ë°±ê·¸ë¼ìš´ë“œ ë¡œë”© ì‹œì‘...")
            self._start_background_embedding_init()
        else:
            print("âš ï¸ ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ê¸°ë³¸ ê¸°ëŠ¥ë§Œ ì‚¬ìš©")
        
        # í´ë°±ìš© ê¸°ë³¸ ëª…ì–¸ (ì„ë² ë”© ì‹œìŠ¤í…œ ì‹¤íŒ¨ ì‹œ)
        self.fallback_quotes = [
            {
                "text": "ê°€ì¥ ì–´ë‘ìš´ ë°¤ë„ ê²°êµ­ì€ ëë‚˜ê³ , í•´ëŠ” ë– ì˜¤ë¥¸ë‹¤.",
                "author": "ë¹…í„° ìœ„ê³ ",
                "category": "hope"
            },
            {
                "text": "ë„˜ì–´ì§€ëŠ” ê²ƒì€ ì‹¤íŒ¨ê°€ ì•„ë‹ˆë‹¤. ë„˜ì–´ì§„ ìë¦¬ì— ë¨¸ë¬´ëŠ” ê²ƒì´ ì‹¤íŒ¨ë‹¤.",
                "author": "ê³µì",
                "category": "resilience"
            },
            {
                "text": "í–‰ë³µì€ ìŠµê´€ì´ë‹¤. ê·¸ê²ƒì„ ëª¸ì— ì§€ë‹ˆë¼.",
                "author": "í—ˆë²„ë“œ",
                "category": "happiness"
            }
        ]
    
    def _start_background_embedding_init(self):
        """ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì„ë² ë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        def background_init():
            global EMBEDDING_LOADING, EMBEDDING_AVAILABLE
            EMBEDDING_LOADING = True
            start_time = time.time()
            
            try:
                print("ğŸ“¥ ì„ë² ë”© ì‹œìŠ¤í…œ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹œì‘...")
                
                # ëŸ°íƒ€ì„ì— ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¬ì‹œë„
                import_start = time.time()
                try:
                    import faiss
                    from sentence_transformers import SentenceTransformer
                    import_time = time.time() - import_start
                    print(f"âœ… ëŸ°íƒ€ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ ({import_time:.2f}ì´ˆ)")
                except ImportError as import_err:
                    print(f"âŒ ëŸ°íƒ€ì„ import ì‹¤íŒ¨: {import_err}")
                    raise import_err
                
                # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
                faiss_start = time.time()
                print("ğŸ“ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...")
                self.faiss_index = faiss.read_index("vectorDB/FAISS/quotes_cosine_faiss.index")
                faiss_time = time.time() - faiss_start
                print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ ({faiss_time:.2f}ì´ˆ)")
                
                # SentenceTransformer ëª¨ë¸ ë¡œë“œ
                model_start = time.time()
                print("ğŸ§  SentenceTransformer ëª¨ë¸ ë¡œë“œ ì‹œì‘...")
                print("  ğŸ“¥ HuggingFace Hubì—ì„œ ëª¨ë¸ í™•ì¸ ì¤‘...")
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                try:
                    import psutil
                    memory_before = psutil.virtual_memory().used / (1024**3)
                    print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë¡œë“œ ì „): {memory_before:.2f}GB")
                    memory_tracking = True
                except ImportError:
                    print("  âš ï¸ psutil ì—†ìŒ - ë©”ëª¨ë¦¬ ì¶”ì  ê±´ë„ˆë›°ê¸°")
                    memory_tracking = False
                    memory_before = 0
                
                # ìƒì„¸ ì§„ë‹¨ì„ ìœ„í•œ ë‹¨ê³„ë³„ ë¡œë“œ
                try:
                    # ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ ìš°ì„  í™•ì¸
                    local_models_dir = "./models/sentence-transformers"
                    
                    # ë¡œì»¬ ë‹¤êµ­ì–´ ëª¨ë¸ë§Œ ì‚¬ìš© (Cursor Rules ì¤€ìˆ˜)
                    multilingual_model = "paraphrase-multilingual-mpnet-base-v2"
                    local_multilingual = os.path.join(local_models_dir, multilingual_model)
                    
                    # ë¡œì»¬ ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                    if os.path.exists(local_multilingual):
                        model_path = local_multilingual
                        model_type = "ë‹¤êµ­ì–´ ëª¨ë¸ (ë¡œì»¬)"
                        print(f"  ğŸ  ë¡œì»¬ ë‹¤êµ­ì–´ ëª¨ë¸ ì‚¬ìš©: {model_path}")
                    else:
                        raise FileNotFoundError(f"ë¡œì»¬ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {local_multilingual}")
                        
                    # ë¡œì»¬ ìºì‹œ í´ë” ì‚¬ìš©í•˜ì—¬ ì˜¨ë¼ì¸ ë‹¤ìš´ë¡œë“œ ê¸ˆì§€
                    cache_check_start = time.time()
                    self.embedding_model = SentenceTransformer(
                        multilingual_model, 
                        cache_folder=local_models_dir
                    )
                    model_time = time.time() - model_start
                    cache_time = time.time() - cache_check_start
                    
                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                    if memory_tracking:
                        memory_after = psutil.virtual_memory().used / (1024**3)
                        memory_used = memory_after - memory_before
                        print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë¡œë“œ í›„): {memory_after:.2f}GB (ì¦ê°€: {memory_used:.2f}GB)")
                    
                    print(f"âœ… {model_type} ë¡œë“œ ì™„ë£Œ ({model_time:.2f}ì´ˆ, ì‹¤ì œ: {cache_time:.2f}ì´ˆ)")
                    
                except Exception as model_err:
                    print(f"âŒ ëª¨ë¸ ë¡œë“œ ìƒì„¸ ì˜¤ë¥˜: {model_err}")
                    raise model_err
                
                # ëª…ì–¸ ë°ì´í„°ì…‹ ë¡œë“œ
                dataset_start = time.time()
                print("ğŸ“Š ëª…ì–¸ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
                self.quotes_df = pd.read_csv("Dataset/quotes_with_insights_combined.csv")
                dataset_time = time.time() - dataset_start
                print(f"âœ… ëª…ì–¸ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ ({len(self.quotes_df)}ê°œ ëª…ì–¸, {dataset_time:.2f}ì´ˆ)")
                
                # ì‹œìŠ¤í…œ í™œì„±í™”
                self.embedding_system_available = True
                EMBEDDING_AVAILABLE = True
                EMBEDDING_LOADING = False
                
                total_time = time.time() - start_time
                print(f"ğŸ‰ ì„ë² ë”© ì‹œìŠ¤í…œ ì™„ì „ í™œì„±í™”! (ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ)")
                print(f"ğŸ“Š ì‹œê°„ ë¶„ì„: Import({import_time:.2f}s) + FAISS({faiss_time:.2f}s) + Model({model_time:.2f}s) + Dataset({dataset_time:.2f}s)")
                
            except Exception as e:
                error_time = time.time() - start_time
                print(f"âŒ ì„ë² ë”© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ ({error_time:.2f}ì´ˆ í›„): {e}")
                print(f"âŒ ì—ëŸ¬ ì„¸ë¶€ì‚¬í•­: {type(e).__name__}: {str(e)}")
                print("ğŸ”„ í´ë°± ì‹œìŠ¤í…œ ê³„ì† ì‚¬ìš©")
                self.embedding_system_available = False
                EMBEDDING_AVAILABLE = False
                EMBEDDING_LOADING = False
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
        init_thread = threading.Thread(target=background_init, daemon=True)
        init_thread.start()
        print(f"ğŸš€ ë°±ê·¸ë¼ìš´ë“œ ì„ë² ë”© ì´ˆê¸°í™” ìŠ¤ë ˆë“œ ì‹œì‘ë¨ (Thread ID: {init_thread.ident})")
    

    
    def _get_conversation_context(self):
        """ëŒ€í™” ì „ì²´ ì»¨í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°"""
        if not self.chat_history.messages:
            return ""
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë“¤ë§Œ ì¶”ì¶œí•˜ì—¬ ê°ì •/ìƒí™© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        user_messages = [
            msg.content for msg in self.chat_history.messages 
            if isinstance(msg, HumanMessage)
        ]
        
        # ì „ì²´ ëŒ€í™”ë¥¼ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
        conversation_context = " ".join(user_messages)
        
        return conversation_context
    
    def _get_summarized_context_by_llm(self):
        """LLMì„ í†µí•œ ëŒ€í™” ìš”ì•½ ë° ê°ì • ë¶„ì„"""
        if not self.chat_history.messages:
            return ""
        
        try:
            # ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
            conversation_text = ""
            for msg in self.chat_history.messages[-8:]:  # ìµœê·¼ 8ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
                role = "ì‚¬ìš©ì" if isinstance(msg, HumanMessage) else "ì±—ë´‡"
                conversation_text += f"{role}: {msg.content}\n"
            
            # LLMì—ê²Œ ëŒ€í™” ìš”ì•½ ìš”ì²­
            summary_prompt = f"""
ë‹¤ìŒ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì • ìƒíƒœì™€ ìƒí™©ì„ 30-40ë‹¨ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
ëª…ì–¸ ì¶”ì²œì„ ìœ„í•œ í•µì‹¬ í‚¤ì›Œë“œì™€ ê°ì •ì„ í¬í•¨í•´ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
{conversation_text}

ìš”ì•½ (30-40ë‹¨ì–´):"""

            # Solar APIë¡œ ìš”ì•½ ìƒì„±
            summary_response = self.llm.invoke(summary_prompt)
            summarized_context = str(summary_response.content).strip()
            
            print(f"ğŸ§  LLM ëŒ€í™” ìš”ì•½: {summarized_context}")
            return summarized_context
            
        except Exception as e:
            print(f"âš ï¸ LLM ìš”ì•½ ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ì¡´ ë‹¨ìˆœ ê²°í•© ë°©ì‹ ì‚¬ìš©
            return self._get_conversation_context()
    
    def get_personalized_quote(self):
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°œì¸í™”ëœ ëª…ì–¸ ê²€ìƒ‰"""
        if not self.embedding_system_available:
            # ì„ë² ë”© ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€ ì‹œ í´ë°±
            return random.choice(self.fallback_quotes)
        
        try:
            # LLMì„ í†µí•œ ëŒ€í™” ìš”ì•½ ì‚¬ìš©
            conversation_context = self._get_summarized_context_by_llm()
            
            if not conversation_context.strip():
                # ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ í´ë°±
                return random.choice(self.fallback_quotes)
            
            print(f"ğŸ” ëª…ì–¸ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸: {conversation_context}")
            
            # ìš”ì•½ëœ ëŒ€í™”ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            user_embedding = self.embedding_model.encode([conversation_context], convert_to_tensor=False)
            user_embedding = user_embedding / np.linalg.norm(user_embedding)  # ì •ê·œí™”
            
            # FAISS ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            distances, indices = self.faiss_index.search(np.array(user_embedding), 1)
            
            # ê°€ì¥ ìœ ì‚¬í•œ ëª…ì–¸ ì„ íƒ
            best_match_idx = indices[0][0]
            similarity_score = distances[0][0]
            
            quote_text = self.quotes_df["quote"].iloc[best_match_idx]
            quote_author = self.quotes_df["author"].iloc[best_match_idx]
            quote_category = self.quotes_df["category"].iloc[best_match_idx]
            
            print(f"âœ¨ ì„ë² ë”© ê¸°ë°˜ ëª…ì–¸ ì„ íƒ: {quote_text[:50]}... (ìœ ì‚¬ë„: {similarity_score:.4f})")
            
            return {
                "text": quote_text,
                "author": quote_author,
                "category": quote_category,
                "similarity": float(similarity_score),
                "method": "llm_summary_embedding_search",
                "summary_context": conversation_context
            }
            
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ í´ë°± ì‹œìŠ¤í…œ ì‚¬ìš©")
            fallback_quote = random.choice(self.fallback_quotes)
            fallback_quote["method"] = "fallback_random"
            return fallback_quote
    
    def chat_once(self, user_input):
        """ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ Solar APIë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
            formatted_history = ""
            if self.chat_history.messages:
                formatted_history = "\n".join([
                    f"{'User' if isinstance(msg, HumanMessage) else 'Assistant'}: {msg.content}"
                    for msg in self.chat_history.messages[-6:]  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
                ])
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = ChatPromptTemplate.from_messages([
                ("system", SYSTEM_PROMPT),
                ("user", "{user_input}")
            ])
            
            # Solar API í˜¸ì¶œ
            chain = prompt | self.llm
            full_input = f"{formatted_history}\n\nUser: {user_input}" if formatted_history else user_input
            
            response = chain.invoke({
                "user_input": full_input
            })
            
            ai_response = str(response.content)
            
            # ì±„íŒ… íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.chat_history.add_messages([
                HumanMessage(content=user_input),
                AIMessage(content=ai_response)
            ])
            
            self.conversation_count += 1
            
            return ai_response
            
        except Exception as e:
            print(f"Solar API ì—ëŸ¬: {e}")
            return "ì£„ì†¡í•´ìš”, ì§€ê¸ˆ ëŒ€í™”í•˜ëŠ”ë° ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œê² ì–´ìš”?"
    
    def get_user_messages(self):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ëª©ë¡ ë°˜í™˜"""
        return [msg.content for msg in self.chat_history.messages if isinstance(msg, HumanMessage)]
    
    def get_ai_messages(self):
        """AI ë©”ì‹œì§€ ëª©ë¡ ë°˜í™˜"""
        return [msg.content for msg in self.chat_history.messages if isinstance(msg, AIMessage)]

# ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
chatbot_sessions = {}
session_lock = threading.Lock()

def get_chatbot_instance(user_id, thread_num):
    """ì‚¬ìš©ìë³„ Solar ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
    session_key = f"{user_id}_{thread_num}"
    
    with session_lock:
        if session_key not in chatbot_sessions:
            chatbot_sessions[session_key] = {
                'chatbot': SolarChatbot(),
                'created_at': datetime.now(),
                'last_used': datetime.now()
            }
            print(f"ğŸš€ ìƒˆë¡œìš´ Solar ì±—ë´‡ ì„¸ì…˜ ìƒì„±: {session_key}")
        else:
            chatbot_sessions[session_key]['last_used'] = datetime.now()
    
    return chatbot_sessions[session_key]['chatbot']

@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    global EMBEDDING_LOADING, EMBEDDING_AVAILABLE
    
    # ì„ë² ë”© ì‹œìŠ¤í…œ ìƒíƒœ ê²°ì •
    if EMBEDDING_AVAILABLE:
        embedding_status = "âœ… ACTIVE"
        message = "ğŸ‰ Solar API + ê°œì¸í™” ëª…ì–¸ ì¶”ì²œ ì‹œìŠ¤í…œ ì™„ì „ í™œì„±í™”!"
    elif EMBEDDING_LOADING:
        embedding_status = "ğŸ”„ LOADING"
        message = "ğŸ“¥ Solar API ë™ì‘ ì¤‘ + ì„ë² ë”© ì‹œìŠ¤í…œ ë°±ê·¸ë¼ìš´ë“œ ë¡œë”© ì¤‘..."
    else:
        embedding_status = "âš ï¸ FALLBACK"
        message = "ğŸ”¥ Solar API ë™ì‘ ì¤‘ + ê¸°ë³¸ ëª…ì–¸ ì‹œìŠ¤í…œ ì‚¬ìš©"
    
    return jsonify({
        'status': 'OK',
        'timestamp': datetime.now().isoformat(),
        'activeConversations': len(chatbot_sessions),
        'model': 'Solar Pro API',
        'embedding_system': embedding_status,
        'embedding_available': EMBEDDING_AVAILABLE,
        'embedding_loading': EMBEDDING_LOADING,
        'message': message
    })

@app.route('/api/chat/send', methods=['POST'])
def send_message():
    """ë©”ì‹œì§€ ì „ì†¡ API - ì‹¤ì œ Solar API + ì„ë² ë”© ê²€ìƒ‰ ì‚¬ìš©"""
    try:
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ['userId', 'threadNum', 'content']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'Missing required field: {field}'}), 400
        
        user_id = data['userId']
        thread_num = data['threadNum']
        content = data['content']
        
        print(f"ğŸ¤– Solar API í˜¸ì¶œ - User: {user_id}, Message: {content}")
        
        # Solar ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        chatbot = get_chatbot_instance(user_id, thread_num)
        
        # Solar APIë¡œ ì‘ë‹µ ìƒì„±
        ai_response = chatbot.chat_once(content)
        
        print(f"âœ¨ Solar API ì‘ë‹µ: {ai_response}")
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            'userId': user_id,
            'threadNum': thread_num,
            'timestamp': datetime.now().isoformat(),
            'status': 'completed',
            'content': ai_response,
            'quote': None,
            'model': 'Solar Pro',
            'embedding_system': 'FAISS'
        }
        
        # ëŒ€í™” íšŸìˆ˜ í™•ì¸ (4ë²ˆì§¸ ëŒ€í™” ì‹œ ê°œì¸í™”ëœ ëª…ì–¸ ìƒì„±)
        user_messages = chatbot.get_user_messages()
        if len(user_messages) >= 4:
            quote = chatbot.get_personalized_quote()
            response_data['quote'] = {
                'id': str(uuid.uuid4()),
                'text': quote['text'],
                'author': quote['author'],
                'category': quote['category'],
                'similarity': quote.get('similarity', 0.0),
                'method': quote.get('method', 'unknown')
            }
            print(f"ğŸ“œ ê°œì¸í™”ëœ ëª…ì–¸ ìƒì„±: {quote['text'][:50]}... - {quote['author']}")
            print(f"ğŸ” ì„ íƒ ë°©ë²•: {quote.get('method', 'unknown')}")
        
        return jsonify(response_data)
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return jsonify({
            'error': str(e),
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'model': 'Solar Pro'
        }), 500

@app.route('/api/chat/status', methods=['GET'])
def get_status():
    """ìƒíƒœ í™•ì¸ API (í´ë§ìš©)"""
    try:
        user_id = request.args.get('userId')
        thread_num = request.args.get('threadNum')
        
        if not user_id or not thread_num:
            return jsonify({'error': 'Missing userId or threadNum'}), 400
        
        # ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        session_key = f"{user_id}_{thread_num}"
        
        if session_key in chatbot_sessions:
            chatbot = chatbot_sessions[session_key]['chatbot']
            
            # ìµœê·¼ AI ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
            ai_messages = chatbot.get_ai_messages()
            latest_response = ai_messages[-1] if ai_messages else ""
            
            return jsonify({
                'userId': user_id,
                'threadNum': thread_num,
                'timestamp': datetime.now().isoformat(),
                'status': 'completed',
                'content': latest_response,
                'quote': None,
                'model': 'Solar Pro',
                'embedding_system': 'FAISS'
            })
        else:
            return jsonify({
                'userId': user_id,
                'threadNum': thread_num,
                'timestamp': datetime.now().isoformat(),
                'status': 'pending',
                'content': '',
                'quote': None,
                'model': 'Solar Pro',
                'embedding_system': 'FAISS'
            })
            
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error',
            'timestamp': datetime.now().isoformat(),
            'model': 'Solar Pro'
        }), 500

if __name__ == '__main__':
    print("ğŸš€ Solar API + ì„ë² ë”© ê¸°ë°˜ LLM ì„œë²„ ì‹œì‘ ì¤‘...")
    print("ğŸ“¡ í¬íŠ¸: 3001")
    print("ğŸ”¥ ëª¨ë¸: Solar Pro API")
    print("ğŸ§  ì„ë² ë”©: SentenceTransformer + FAISS")
    print("ğŸ“Š ë°ì´í„°ì…‹: quotes_with_insights_combined.csv")
    print("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ: True")
    print("ğŸŒ CORS í™œì„±í™”ë¨")
    print("âœ¨ ê°œì¸í™”ëœ ëª…ì–¸ ì¶”ì²œ ì‹œìŠ¤í…œ!")
    
    app.run(host='0.0.0.0', port=3001, debug=False, use_reloader=False)
