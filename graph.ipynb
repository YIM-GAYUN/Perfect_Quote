{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f2bec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 챗봇에 필요한 라이브러리 불러오기\n",
    "\n",
    "# import langchain and langgraph libs\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# system prompt\n",
    "from utils.system_prompt import SYSTEM_PROMPT\n",
    "from utils.analysis_prompt import ANALYSIS_PROMPT\n",
    "\n",
    "# others\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# type hint\n",
    "from typing import TypedDict, List, Dict, Any, Annotated, Optional\n",
    "\n",
    "# load env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a538987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇에 필요한 랭그래프 상태(state) 구현하기\n",
    "\n",
    "# define state for chatbot\n",
    "class ChatbotState(TypedDict):\n",
    "    user_id: Annotated[str, \"User ID\"]\n",
    "    thread_num: Annotated[str, \"Session ID\"]\n",
    "    user_message: Annotated[str, \"User Message\"] # 사용자의 입력 메시지\n",
    "    chatbot_message: Annotated[str, \"Chatbot Message\"] # 챗봇의 응답 메시지\n",
    "    timestamp: Annotated[str, \"Timestamp of the conversation\"] # 사용자와 챗봇의 응답 시간 기록 값\n",
    "    chat_history: Annotated[ChatMessageHistory, \"chat history of user and ai\"] # 처음부터 끝까지의 대화 히스토리\n",
    "    chat_summary: Annotated[str, \"Summary of the conversation\"] # 대화 내용을 요약한 문장\n",
    "    status: Annotated[str, \"Status of the conversation\"] # 웹과의 소통 상태 값 (pending, success, error 등)\n",
    "    \n",
    "    quote: Annotated[str, \"Quote for the conversation\"] # 챗봇이 추출한 명언 값\n",
    "    author: Annotated[str, \"Author of the quote\"] # 챗봇이 추출한 명언의 저자 값\n",
    "    keywords: Annotated[Dict[str, str], \"Keywords of the conversation\"] # 대화 내용을 키워드로 분류한 문장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ea563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹과 소통할 때 쓰일 사용자의 id와 쓰레드 값\n",
    "\n",
    "# # identify the user\n",
    "# def identify_user(state: ChatbotState) -> ChatbotState:\n",
    "#     return {**state}\n",
    "\n",
    "# # initialize the session\n",
    "# def initialize_session(state: ChatbotState) -> ChatbotState:\n",
    "#     return {**state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac741b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d66ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 그래프에 쓰일 노드 정의하기\n",
    "\n",
    "# 사용자의 입력 값 검증 -> 챗봇의 응답 생성 -> 대화 히스토리 저장\n",
    "# 대화 히스토리 분석 -> 끝\n",
    "# 끝\n",
    "\n",
    "# 위 순서로 진행된다.\n",
    "\n",
    "\n",
    "def _init_llm():\n",
    "    return ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_user_input(state: ChatbotState) -> ChatbotState:\n",
    "    user_input = state[\"user_message\"]\n",
    "    if not isinstance(user_input, str):\n",
    "        raise TypeError(\"User message must be a string\")\n",
    "    \n",
    "    user_input = user_input.strip()\n",
    "    if not user_input:\n",
    "        raise ValueError(\"User message cannot be empty\")\n",
    "        \n",
    "    if len(user_input) > 150:\n",
    "        raise ValueError(\"User message cannot be longer than 150 characters\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"user_message\": user_input\n",
    "    }\n",
    "\n",
    "def _build_chain():\n",
    "    llm = _init_llm()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", SYSTEM_PROMPT),\n",
    "        (\"user\", \"{user_input}\")\n",
    "    ])\n",
    "    chain = prompt | llm  \n",
    "    return chain\n",
    "\n",
    "\n",
    "def chatbot(state: ChatbotState) -> ChatbotState:\n",
    "    # Initialize chat history if empty\n",
    "    chat_history = state[\"chat_history\"]\n",
    "    if not chat_history:\n",
    "        chat_history = ChatMessageHistory()\n",
    "        \n",
    "    # Format chat history for prompt if needed\n",
    "    formatted_history = \"\"\n",
    "    if chat_history.messages:\n",
    "        formatted_history = \"\\n\".join([\n",
    "            f\"{'User' if isinstance(msg, HumanMessage) else 'Assistant'}: {msg.content}\"\n",
    "            for msg in chat_history.messages\n",
    "        ])\n",
    "        \n",
    "    chain = _build_chain()\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": f\"{formatted_history}\\n\\nUser: {state['user_message']}\" if formatted_history else state[\"user_message\"]\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"chatbot_message\": str(response.content),\n",
    "    }\n",
    "\n",
    "def save_history(state: ChatbotState) -> ChatbotState:\n",
    "    chat_history = state[\"chat_history\"]\n",
    "    chat_history.add_messages([\n",
    "        HumanMessage(content=state[\"user_message\"]),\n",
    "        AIMessage(content=state[\"chatbot_message\"])\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"chat_history\": chat_history \n",
    "    }\n",
    "\n",
    "def _init_analysis_llm():\n",
    "    return ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "def _build_analysis_chain():\n",
    "    llm = _init_analysis_llm()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", ANALYSIS_PROMPT),\n",
    "        (\"user\", \"{chat_history}\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    return chain\n",
    "\n",
    "def analyze_chat_history(state: ChatbotState) -> ChatbotState:\n",
    "    chat_history = state[\"chat_history\"]\n",
    "\n",
    "    # 대화 턴 수가 10턴 이상이면 분석을 한다.\n",
    "    if len(chat_history.messages) >= 10:\n",
    "        analysis_llm = _init_analysis_llm()\n",
    "        analysis_chain = _build_analysis_chain()\n",
    "        analysis_response = analysis_chain.invoke({\n",
    "            \"chat_history\": chat_history\n",
    "        })\n",
    "        analysis_result = analysis_response.content\n",
    "        return {\n",
    "            **state,\n",
    "            \"analysis_result\": analysis_result\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            **state,\n",
    "            \"analysis_result\": None\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88ef30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분기 엣지 정의\n",
    "def should_analyze_chat_history(state: ChatbotState) -> bool:\n",
    "    return len(state[\"chat_history\"].messages) >= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9218e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "StateGraph.add_conditional_edges() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m workflow.add_edge(\u001b[33m\"\u001b[39m\u001b[33mchatbot\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msave_history\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 조건부 분기 추가\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_conditional_edges\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshould_analyze_chat_history\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manalyze_chat_history\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 10개 이상이면 분석\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# 10개 미만이면 종료\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# analyze_chat_history에서 종료로 가는 엣지\u001b[39;00m\n\u001b[32m     28\u001b[39m workflow.add_edge(\u001b[33m\"\u001b[39m\u001b[33manalyze_chat_history\u001b[39m\u001b[33m\"\u001b[39m, END)\n",
      "\u001b[31mTypeError\u001b[39m: StateGraph.add_conditional_edges() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "# 위에서 정의한 노드를 연결하여 하나의 그래프를 구성한다.\n",
    "# 노드와 노드는 엣지로 연결한다.\n",
    "# 맨 처음과 시작은 START와 END로 연결한다.\n",
    "# 그래프 구성\n",
    "workflow = StateGraph(ChatbotState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"validate_user_input\", validate_user_input)\n",
    "workflow.add_node(\"chatbot\", chatbot)\n",
    "workflow.add_node(\"save_history\", save_history)\n",
    "workflow.add_node(\"analyze_chat_history\", analyze_chat_history)\n",
    "\n",
    "# 엣지 연결\n",
    "workflow.add_edge(START, \"validate_user_input\")\n",
    "workflow.add_edge(\"validate_user_input\", \"chatbot\")\n",
    "workflow.add_edge(\"chatbot\", \"save_history\")\n",
    "\n",
    "# 조건부 분기 추가\n",
    "workflow.add_conditional_edges(\n",
    "    \"save_history\",\n",
    "    should_analyze_chat_history,\n",
    "    path_map={\n",
    "        True: \"analyze_chat_history\",\n",
    "        False: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# analyze_chat_history에서 종료로 가는 엣지\n",
    "workflow.add_edge(\"analyze_chat_history\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 그래프를 실행하는 함수이다.\n",
    "def run_chatbot_once(graph, state, user_input):\n",
    "    \"\"\"단일 턴 대화 실행\"\"\"\n",
    "    # 현재 상태에 새로운 사용자 입력 설정\n",
    "    state[\"user_message\"] = user_input\n",
    "\n",
    "    # 그래프 실행\n",
    "    result = graph.invoke(state)\n",
    "\n",
    "    return result\n",
    "\n",
    "def print_conversation_result(result, turn_number):\n",
    "    \"\"\"대화 결과 출력\"\"\"\n",
    "    print(f\"\\n=== Turn {turn_number} ===\")\n",
    "    print(f\"사용자: {result['user_message']}\")\n",
    "    print(f\"챗봇: {result['chatbot_message']}\")\n",
    "    print(f\"시간: {result['timestamp']}\")\n",
    "    print(f\"유효한 입력: {result['status']}\")\n",
    "    print(f\"히스토리 메시지 수: {len(result['chat_history'].messages)}\")\n",
    "\n",
    "def print_chat_history(chat_history):\n",
    "    \"\"\"전체 채팅 히스토리 출력\"\"\"\n",
    "    print(\"\\n=== 전체 채팅 히스토리 ===\")\n",
    "    for i, msg in enumerate(chat_history.messages, 1):\n",
    "        role = \"사용자\" if msg.type == \"human\" else \"챗봇\"\n",
    "        content = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "        print(f\"{i}. {role}: {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfac7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 상태 값을 설정한다.\n",
    "# 대화가 진행되면서 상태 값이 업데이트된다. 이 업데이트된 값을 통해서 웹과 소통할 수 있다.\n",
    "\n",
    "initial_state = {\n",
    "    \"user_id\": \"user1\",\n",
    "    \"thread_num\": \"thread1\",\n",
    "    \"user_message\": \"\",\n",
    "    \"chatbot_message\": \"\",\n",
    "    \"timestamp\": \"\",\n",
    "    \"chat_history\": ChatMessageHistory(),\n",
    "    \"status\": \"\",\n",
    "    \"quote\": \"\",\n",
    "    \"author\": \"\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티턴으로 대화를 실행하는 함수를 정의하여 결과를 보자.\n",
    "# 사용자가 exit를 입력하면 대화를 종료한다.\n",
    "import time\n",
    "def run_multiple_turns(graph, num_turns=10):\n",
    "    \"\"\"여러 턴 대화 실행\"\"\"\n",
    "    # 최초 상태 정의\n",
    "    initial_state = {\n",
    "        \"user_id\": \"user1\",\n",
    "        \"thread_num\": \"thread1\",\n",
    "        \"user_message\": \"\",\n",
    "        \"chatbot_message\": \"\",\n",
    "        \"timestamp\": \"\",\n",
    "        \"chat_history\": ChatMessageHistory(),\n",
    "        \"status\": \"\",\n",
    "        \"quote\": \"\",\n",
    "        \"author\": \"\",\n",
    "    }\n",
    "\n",
    "    # 대화 실행\n",
    "    current_state = initial_state\n",
    "    for i in range(num_turns):\n",
    "        user_input = input(\"사용자: \")\n",
    "        time.sleep(0.2)\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        time.sleep(0.2)\n",
    "        current_state = run_chatbot_once(graph, current_state, user_input)\n",
    "        print_conversation_result(current_state, i + 1)\n",
    "        print_chat_history(current_state[\"chat_history\"])\n",
    "    return current_state    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12650613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Turn 1 ===\n",
      "사용자: 안녕\n",
      "챗봇: 안녕! 오랜만이네. 어떻게 지냈어? 최근에 재미있는 일 있었어?\n",
      "시간: \n",
      "유효한 입력: \n",
      "히스토리 메시지 수: 2\n",
      "\n",
      "=== 전체 채팅 히스토리 ===\n",
      "1. 사용자: 안녕\n",
      "2. 챗봇: 안녕! 오랜만이네. 어떻게 지냈어? 최근에 재미있는 일 있었어?\n",
      "\n",
      "=== Turn 2 ===\n",
      "사용자: 그래\n",
      "챗봇: 그래, 최근에 별일 없었어? 나도 시간이 날 때마다 책 읽고, 산책하는 게 좀 재미있더라. 너도 어떤 취미 생활 해?\n",
      "시간: \n",
      "유효한 입력: \n",
      "히스토리 메시지 수: 4\n",
      "\n",
      "=== 전체 채팅 히스토리 ===\n",
      "1. 사용자: 안녕\n",
      "2. 챗봇: 안녕! 오랜만이네. 어떻게 지냈어? 최근에 재미있는 일 있었어?\n",
      "3. 사용자: 그래\n",
      "4. 챗봇: 그래, 최근에 별일 없었어? 나도 시간이 날 때마다 책 읽고, 산책하는 게 좀 재미있더라. 너도 어떤 취미 생활 해?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_id': 'user1',\n",
       " 'thread_num': 'thread1',\n",
       " 'user_message': '그래',\n",
       " 'chatbot_message': '그래, 최근에 별일 없었어? 나도 시간이 날 때마다 책 읽고, 산책하는 게 좀 재미있더라. 너도 어떤 취미 생활 해?',\n",
       " 'timestamp': '',\n",
       " 'chat_history': InMemoryChatMessageHistory(messages=[HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕! 오랜만이네. 어떻게 지냈어? 최근에 재미있는 일 있었어?', additional_kwargs={}, response_metadata={}), HumanMessage(content='그래', additional_kwargs={}, response_metadata={}), AIMessage(content='그래, 최근에 별일 없었어? 나도 시간이 날 때마다 책 읽고, 산책하는 게 좀 재미있더라. 너도 어떤 취미 생활 해?', additional_kwargs={}, response_metadata={})]),\n",
       " 'status': '',\n",
       " 'quote': '',\n",
       " 'author': ''}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_multiple_turns(graph, num_turns=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
